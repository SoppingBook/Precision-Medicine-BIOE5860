{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8023fbe4-c3ef-4603-9a28-53b4c79cdb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code compresses PROCEDURES_ICD9, and DIAGNOSES_ICD9 into single entries per admission (sorted by SEQ_NUM)\n",
    "#and merges this data with the ADMISSIONS dataframe, providing two separate dataframes with this merged structure.\n",
    "#One dataframe corresponds to patients diagnosed with specified ICD-9 codes and the other contains the control patients.\n",
    "\n",
    "#Updates made:\n",
    "# 1. Separated lab events from the merged dataframes into separate dataframes to support easier unpacking later.\n",
    "# 2. Fixed logic for pulling SUBJECT_ID for controls patients to prevent leakage of diseased patients into controls DF\n",
    "# 3. Used chunking while processing the large LABEVENTS CSV to prevent memory overload and crashes\n",
    "# 4. Specified labs specific to aortic dissection and pulled corresponding ITEMNAMES from Lab_Item_Codes.txt.\n",
    "#    Only patients with these labs exist in the controls LABEVENTS DF and the diseased patients LABEVENTS DF\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ADMISSIONS = pd.read_csv(r\"C:\\BIOE5860_Data\\ADMISSIONS.csv\")\n",
    "DIAGNOSES_ICD = pd.read_csv(r\"C:\\BIOE5860_Data\\DIAGNOSES_ICD.csv\")\n",
    "PATIENTS = pd.read_csv(r\"C:\\BIOE5860_Data\\PATIENTS.csv\")\n",
    "PROCEDURES_ICD = pd.read_csv(r\"C:\\BIOE5860_Data\\PROCEDURES_ICD.csv\")\n",
    "\n",
    "#Input ICD9 code that you want to look at here:\n",
    "my_icd9_code = [\"44100\", \"44101\", \"44102\", \"44103\"] #441 is arotic dissection. Change to 421 for bacterial endocarditis\n",
    "#check what any following numbers would be in the ICD9 code\n",
    "#need to update to be 441.00, 441.01, 441.02, 441.03\n",
    "\n",
    "#Returns patients with aortic dissection\n",
    "AD_SUBJECT_ID = DIAGNOSES_ICD.loc[\n",
    "    DIAGNOSES_ICD[\"ICD9_CODE\"].astype(str).isin(my_icd9_code),\n",
    "    \"SUBJECT_ID\"\n",
    "].unique() \n",
    "\n",
    "CONTROL_SUBJECT_ID = DIAGNOSES_ICD.loc[\n",
    "    ~DIAGNOSES_ICD[\"SUBJECT_ID\"].isin(AD_SUBJECT_ID), \n",
    "    \"SUBJECT_ID\"\n",
    "].unique()\n",
    "\n",
    "#Returns the specific admissions where aortic dissection was diagnosed\n",
    "AD_HADM_ID = DIAGNOSES_ICD.loc[\n",
    "    DIAGNOSES_ICD[\"ICD9_CODE\"].astype(str).isin(my_icd9_code),\n",
    "    \"HADM_ID\"\n",
    "].unique()\n",
    "\n",
    "\"\"\"\n",
    "Question for Daniel: do we need to filter this again keeping only the first AD diagnosis?\n",
    "\"\"\"\n",
    "\n",
    "#Identify all diagnoses for patients diagnosed with aortic dissection, including for admissions where they were not diagnosed with AD\n",
    "PATIENT_DIAGNOSES = DIAGNOSES_ICD[DIAGNOSES_ICD['SUBJECT_ID'].isin(AD_SUBJECT_ID)]\n",
    "\n",
    "CONTROL_DIAGNOSES = DIAGNOSES_ICD[DIAGNOSES_ICD['SUBJECT_ID'].isin(CONTROL_SUBJECT_ID)]\n",
    "\n",
    "#Return a new dataframe with all the ICD9 codes for each admission condensed into a single row,col val as a compressed list\n",
    "PATIENT_DIAGNOSES = (\n",
    "    PATIENT_DIAGNOSES\n",
    "    .sort_values(['HADM_ID','SEQ_NUM'])\n",
    "    .groupby(['SUBJECT_ID','HADM_ID'])['ICD9_CODE']\n",
    "    .apply(list)\n",
    "    .reset_index(name='DIAGNOSES')\n",
    ")\n",
    "\n",
    "#Return a new dataframe with all the ICD9 codes for each admission condensed into a single row,col val as a compressed list for control patients\n",
    "CONTROL_DIAGNOSES = (\n",
    "    CONTROL_DIAGNOSES\n",
    "    .sort_values(['HADM_ID','SEQ_NUM'])\n",
    "    .groupby(['SUBJECT_ID','HADM_ID'])['ICD9_CODE']\n",
    "    .apply(list)\n",
    "    .reset_index(name='DIAGNOSES')\n",
    ")\n",
    "\n",
    "#Remove DIAGNOSES_ICD to conserve memory since we have already filtered for the relevant data\n",
    "del DIAGNOSES_ICD\n",
    "\n",
    "#Return all procedures for patients diagnosed with AD, including for admissions where they were not diagnosed with AD\n",
    "PATIENT_PROCEDURES = PROCEDURES_ICD[PROCEDURES_ICD['SUBJECT_ID'].isin(AD_SUBJECT_ID)]\n",
    "\n",
    "#identify all procedures for control patients as well\n",
    "CONTROL_PROCEDURES = PROCEDURES_ICD[PROCEDURES_ICD['SUBJECT_ID'].isin(CONTROL_SUBJECT_ID)]\n",
    "\n",
    "#Return a new dataframe with all procedure codes for each admission compressed into a single row,col val as a compressed list\n",
    "PATIENT_PROCEDURES = (\n",
    "    PATIENT_PROCEDURES\n",
    "    .sort_values(['HADM_ID','SEQ_NUM'])\n",
    "    .groupby(['SUBJECT_ID','HADM_ID'])['ICD9_CODE']\n",
    "    .apply(list)\n",
    "    .reset_index(name='PROCEDURE TYPE')\n",
    ")\n",
    "\n",
    "#Return a new dataframe with all procedure codes for each admission compressed into a single row,col val as a compressed list for control patients\n",
    "CONTROL_PROCEDURES = (\n",
    "    CONTROL_PROCEDURES\n",
    "    .sort_values(['HADM_ID','SEQ_NUM'])\n",
    "    .groupby(['SUBJECT_ID','HADM_ID'])['ICD9_CODE']\n",
    "    .apply(list)\n",
    "    .reset_index(name='PROCEDURE TYPE')\n",
    ")\n",
    "\n",
    "#Remove PROCEDURES_ICD to conserve memory since we have already extracted the relevant rows\n",
    "del PROCEDURES_ICD\n",
    "\n",
    "#Return every admission entry for patients who were diagnosed with AD at some point\n",
    "PATIENT_ADMISSIONS = ADMISSIONS[ADMISSIONS['SUBJECT_ID'].isin(AD_SUBJECT_ID)]\n",
    "\n",
    "#pull control group admissions as well\n",
    "CONTROL_ADMISSIONS = ADMISSIONS[ADMISSIONS['SUBJECT_ID'].isin(CONTROL_SUBJECT_ID)]\n",
    "\n",
    "#Remove redundant columns from the other filtered dataframes for a cleaner merge\n",
    "PATIENT_PROCEDURES.drop('SUBJECT_ID',inplace=True,axis=1)\n",
    "PATIENT_DIAGNOSES.drop('SUBJECT_ID',inplace=True,axis=1)\n",
    "CONTROL_PROCEDURES.drop('SUBJECT_ID',inplace=True,axis=1)\n",
    "CONTROL_DIAGNOSES.drop('SUBJECT_ID',inplace=True,axis=1)\n",
    "\n",
    "#Merge the compressed DFs engineered earlier with admissions so that each admission has lab event, diagnosis, and procedure data\n",
    "PATIENT_ADMISSIONS_MERGED = PATIENT_ADMISSIONS.merge(PATIENT_DIAGNOSES, on=\"HADM_ID\", how=\"left\") \\\n",
    "            .merge(PATIENT_PROCEDURES, on=\"HADM_ID\", how=\"left\")\n",
    "\n",
    "CONTROL_ADMISSIONS_MERGED = CONTROL_ADMISSIONS.merge(CONTROL_DIAGNOSES, on=\"HADM_ID\", how=\"left\") \\\n",
    "            .merge(CONTROL_PROCEDURES, on=\"HADM_ID\", how=\"left\")\n",
    "\n",
    "#Rename columns for clarity since there is a text-based labeling column and the ICD-9 diagnosis column\n",
    "PATIENT_ADMISSIONS_MERGED = PATIENT_ADMISSIONS_MERGED.rename(columns={\"DIAGNOSIS\": \"DIAGNOSIS (LABEL)\",\"DIAGNOSES\": \"DIAGNOSIS (ICD_9)\"})\n",
    "CONTROL_ADMISSIONS_MERGED = CONTROL_ADMISSIONS_MERGED.rename(columns={\"DIAGNOSIS\": \"DIAGNOSIS (LABEL)\",\"DIAGNOSES\": \"DIAGNOSIS (ICD_9)\"})\n",
    "\n",
    "#Drop redundant row\n",
    "PATIENT_ADMISSIONS_MERGED.drop(['ROW_ID'],inplace=True,axis=1)\n",
    "CONTROL_ADMISSIONS_MERGED.drop(['ROW_ID'],inplace=True,axis=1)\n",
    "\n",
    "#Identify the admissions where AD was one of the diagnoses given to the patients, excluding admissions where AD was not diagnosed\n",
    "#No need to do this for control group\n",
    "DISEASE_ADMISSIONS = PATIENT_ADMISSIONS_MERGED[PATIENT_ADMISSIONS_MERGED['HADM_ID'].isin(AD_HADM_ID)]\n",
    "DISEASE_ADMISSIONS = DISEASE_ADMISSIONS.copy()\n",
    "\n",
    "#Convert ADMITTIME to datetime for processing\n",
    "DISEASE_ADMISSIONS['ADMITTIME'] = pd.to_datetime(DISEASE_ADMISSIONS[\"ADMITTIME\"], errors=\"coerce\")\n",
    "\n",
    "#convert to datetime for control group\n",
    "CONTROL_ADMISSIONS_MERGED['ADMITTIME'] = pd.to_datetime(CONTROL_ADMISSIONS_MERGED[\"ADMITTIME\"], errors=\"coerce\")\n",
    "\n",
    "#Sort by HADM_ID and ADMITTIME to get a sorted list for processing\n",
    "DISEASE_ADMISSIONS = DISEASE_ADMISSIONS.sort_values(['HADM_ID','ADMITTIME'])\n",
    "\n",
    "#sort control group by HADM_ID and ADMITTIME as well\n",
    "CONTROL_ADMISSIONS_MERGED = CONTROL_ADMISSIONS_MERGED.sort_values(['HADM_ID','ADMITTIME'])\n",
    "\n",
    "#Identify the earliest admission time in which patients were diagnosed with AD\n",
    "DISEASE_FIRST_ADMISSIONS = DISEASE_ADMISSIONS.groupby('SUBJECT_ID',as_index=False)['ADMITTIME'].min()\n",
    "\n",
    "#Rename this column to \"Comparator\" since it will be used for filtering admissions from after the patient was diagnosed with AD\n",
    "DISEASE_FIRST_ADMISSIONS = DISEASE_FIRST_ADMISSIONS.rename(columns={\"ADMITTIME\": \"Comparator\"})\n",
    "\n",
    "#Update ADMISSIONS_MERGED so it now contains all admissions for patients who were diagnosed with AD at some point\n",
    "#Prior and including the admission with their first diagnosis of AD. Admissions after their first diagnosis are excluded\n",
    "PATIENT_ADMISSIONS_MERGED['ADMITTIME'] = pd.to_datetime(PATIENT_ADMISSIONS_MERGED[\"ADMITTIME\"], errors=\"coerce\")\n",
    "PATIENT_ADMISSIONS_MERGED = PATIENT_ADMISSIONS_MERGED.merge(DISEASE_FIRST_ADMISSIONS,on='SUBJECT_ID',how=\"left\")\n",
    "PATIENT_ADMISSIONS_MERGED = PATIENT_ADMISSIONS_MERGED[PATIENT_ADMISSIONS_MERGED['ADMITTIME']<=PATIENT_ADMISSIONS_MERGED['Comparator']]\n",
    "\n",
    "#drop the comparator column now that filtering is done so that the DFs are the same\n",
    "PATIENT_ADMISSIONS_MERGED = PATIENT_ADMISSIONS_MERGED.drop(['Comparator'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80d43a2a-8613-4a41-a37a-64dd3a6d285e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['SUBJECT_ID', 'HADM_ID', 'ADMITTIME', 'DISCHTIME', 'DEATHTIME',\n",
      "       'ADMISSION_TYPE', 'ADMISSION_LOCATION', 'DISCHARGE_LOCATION',\n",
      "       'INSURANCE', 'LANGUAGE', 'RELIGION', 'MARITAL_STATUS', 'ETHNICITY',\n",
      "       'EDREGTIME', 'EDOUTTIME', 'DIAGNOSIS (LABEL)', 'HOSPITAL_EXPIRE_FLAG',\n",
      "       'HAS_CHARTEVENTS_DATA', 'DIAGNOSIS (ICD_9)', 'PROCEDURE TYPE'],\n",
      "      dtype='str')\n",
      "(378, 20)\n",
      "Index(['SUBJECT_ID', 'HADM_ID', 'ADMITTIME', 'DISCHTIME', 'DEATHTIME',\n",
      "       'ADMISSION_TYPE', 'ADMISSION_LOCATION', 'DISCHARGE_LOCATION',\n",
      "       'INSURANCE', 'LANGUAGE', 'RELIGION', 'MARITAL_STATUS', 'ETHNICITY',\n",
      "       'EDREGTIME', 'EDOUTTIME', 'DIAGNOSIS (LABEL)', 'HOSPITAL_EXPIRE_FLAG',\n",
      "       'HAS_CHARTEVENTS_DATA', 'DIAGNOSIS (ICD_9)', 'PROCEDURE TYPE'],\n",
      "      dtype='str')\n",
      "(58462, 20)\n"
     ]
    }
   ],
   "source": [
    "#Thomas's logic retained below\n",
    "\n",
    "print(PATIENT_ADMISSIONS_MERGED.columns)\n",
    "print(PATIENT_ADMISSIONS_MERGED.shape)\n",
    "\n",
    "print(CONTROL_ADMISSIONS_MERGED.columns)\n",
    "print(CONTROL_ADMISSIONS_MERGED.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3c7abe9-6203-496b-9686-8397c5a8f263",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunksize = 50000\n",
    "LAB_EVENTS = pd.read_csv(r\"C:\\BIOE5860_Data\\LABEVENTS.csv\",chunksize=chunksize)\n",
    "LAB_IDS = pd.read_csv(r\"C:\\BIOE5860_Data\\Lab_Item_Codes.txt\", sep=\"\\t\")\n",
    "\n",
    "PATIENT_LAB_EVENTS2 = []\n",
    "CONTROL_LAB_EVENTS2 = []\n",
    "\n",
    "\n",
    "labs_of_interest = [\n",
    "    'TROPONIN', 'D-DIMER', 'CREATININE', 'LACTATE', \n",
    "    'HEMOGLOBIN', 'HEMATOCRIT', 'CK-MB', 'BUN', \n",
    "    'UREA', 'PROCALCITONIN', 'C-REACTIVE', 'CRP', \n",
    "    'PLATELET', 'FIBRINOGEN', 'LDH', 'LACTATE DEHYDROGENASE', \n",
    "    'BILIRUBIN', 'AST', 'ALT', 'GLUCOSE', \n",
    "    'WHITE BLOOD', 'WBC', 'LYMPHOCYTE', 'NEUTROPHIL'\n",
    "]\n",
    "\n",
    "#create one large string which the string matcher will search through\n",
    "pattern = '|'.join(labs_of_interest)\n",
    "\n",
    "#check for any of the strings listed above in the pattern mega-string\n",
    "lab_ids = LAB_IDS[\n",
    "    LAB_IDS['Display'].str.contains(pattern, case=False, na=False)\n",
    "]\n",
    "lab_ids = lab_ids['Code']\n",
    "\n",
    "for EVENT in LAB_EVENTS:\n",
    "\n",
    "    EVENT = EVENT.loc[\n",
    "        EVENT['ITEMID'].isin(lab_ids)\n",
    "    ]\n",
    "    \n",
    "    #Identify all patient labs for patients who were diagnosed with AD at any point\n",
    "    PATIENT_LAB_EVENTS = EVENT[EVENT['SUBJECT_ID'].isin(AD_SUBJECT_ID)]\n",
    "    \n",
    "    #pull control group lab events as well\n",
    "    CONTROL_LAB_EVENTS = EVENT[EVENT['SUBJECT_ID'].isin(CONTROL_SUBJECT_ID)]\n",
    "    \n",
    "    #Remove redundant rows\n",
    "    PATIENT_LAB_EVENTS = PATIENT_LAB_EVENTS.drop(['ROW_ID','VALUE'],axis=1)\n",
    "    CONTROL_LAB_EVENTS = CONTROL_LAB_EVENTS.drop(['ROW_ID','VALUE'],axis=1)\n",
    "    \n",
    "    #Convert CHARTTIME to a datetime for sorting\n",
    "    PATIENT_LAB_EVENTS['CHARTTIME'] = pd.to_datetime(PATIENT_LAB_EVENTS[\"CHARTTIME\"], errors=\"coerce\")\n",
    "    CONTROL_LAB_EVENTS['CHARTTIME'] = pd.to_datetime(CONTROL_LAB_EVENTS[\"CHARTTIME\"], errors=\"coerce\")\n",
    "    \n",
    "    #Only return values that are not na.\n",
    "    PATIENT_LAB_EVENTS = PATIENT_LAB_EVENTS[PATIENT_LAB_EVENTS['HADM_ID'].notna()]\n",
    "    CONTROL_LAB_EVENTS = CONTROL_LAB_EVENTS[CONTROL_LAB_EVENTS['HADM_ID'].notna()]\n",
    "\n",
    "    PATIENT_LAB_EVENTS2.append(PATIENT_LAB_EVENTS)\n",
    "    CONTROL_LAB_EVENTS2.append(CONTROL_LAB_EVENTS)\n",
    "    \n",
    "#Remove LAB_EVENTS to conserve lots of memory since we already have extracted the necessary data\n",
    "del LAB_EVENTS\n",
    "\n",
    "#Construct final labs DFs through concatenation\n",
    "FINAL_PATIENT_LABS = pd.concat(PATIENT_LAB_EVENTS2)\n",
    "FINAL_CONTROL_LABS = pd.concat(CONTROL_LAB_EVENTS2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7167c12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_event_index_filter(PATIENT_ADMISSIONS_MERGED, CONTROL_ADMISSIONS_MERGED, AD_HADM_ID):\n",
    "\n",
    "    PATIENT_ADMISSIONS_MERGED = PATIENT_ADMISSIONS_MERGED.copy()\n",
    "    CONTROL_ADMISSIONS_MERGED = CONTROL_ADMISSIONS_MERGED.copy()\n",
    "\n",
    "    PATIENT_ADMISSIONS_MERGED[\"ADMISSION_INDEX\"] = PATIENT_ADMISSIONS_MERGED.index\n",
    "\n",
    "    PATIENT_ADMISSIONS_MERGED[\"ADMITTIME\"] = pd.to_datetime(\n",
    "        PATIENT_ADMISSIONS_MERGED[\"ADMITTIME\"], errors=\"coerce\"\n",
    "    )\n",
    "\n",
    "    CONTROL_ADMISSIONS_MERGED[\"ADMITTIME\"] = pd.to_datetime(\n",
    "        CONTROL_ADMISSIONS_MERGED[\"ADMITTIME\"], errors=\"coerce\"\n",
    "    )\n",
    "\n",
    "    DISEASE_ADMISSIONS = PATIENT_ADMISSIONS_MERGED[\n",
    "        PATIENT_ADMISSIONS_MERGED[\"HADM_ID\"].isin(AD_HADM_ID)\n",
    "    ].copy()\n",
    "\n",
    "    DISEASE_ADMISSIONS = DISEASE_ADMISSIONS.sort_values(\n",
    "        [\"SUBJECT_ID\", \"ADMITTIME\"]\n",
    "    )\n",
    "\n",
    "    DISEASE_FIRST_ADMISSIONS = (\n",
    "        DISEASE_ADMISSIONS\n",
    "        .groupby(\"SUBJECT_ID\", as_index=False)[\"ADMITTIME\"]\n",
    "        .min()\n",
    "        .rename(columns={\"ADMITTIME\": \"Comparator\"})\n",
    "    )\n",
    "\n",
    "    PATIENT_ADMISSIONS_MERGED = PATIENT_ADMISSIONS_MERGED.merge(\n",
    "        DISEASE_FIRST_ADMISSIONS,\n",
    "        on=\"SUBJECT_ID\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    PATIENT_ADMISSIONS_MERGED = PATIENT_ADMISSIONS_MERGED[\n",
    "        (PATIENT_ADMISSIONS_MERGED[\"Comparator\"].isna()) |\n",
    "        (PATIENT_ADMISSIONS_MERGED[\"ADMITTIME\"] <= PATIENT_ADMISSIONS_MERGED[\"Comparator\"])\n",
    "    ]\n",
    "\n",
    "    PATIENT_ADMISSIONS_MERGED = PATIENT_ADMISSIONS_MERGED.drop(columns=[\"Comparator\"])\n",
    "\n",
    "    PATIENT_ADMISSIONS_MERGED = PATIENT_ADMISSIONS_MERGED.set_index(\"ADMISSION_INDEX\")\n",
    "    PATIENT_ADMISSIONS_MERGED = PATIENT_ADMISSIONS_MERGED.sort_index()\n",
    "\n",
    "    return PATIENT_ADMISSIONS_MERGED, CONTROL_ADMISSIONS_MERGED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "944292af",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATIENT_ADMISSIONS_MERGED, CONTROL_ADMISSIONS_MERGED = apply_event_index_filter(PATIENT_ADMISSIONS_MERGED, CONTROL_ADMISSIONS_MERGED, AD_HADM_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "373a8875-2261-4d82-84ac-923810f87831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<StringArray>\n",
      "['44101',  '5185', '99674', '56962',  '9971', '42731', '99859', '70703',\n",
      "  '5793',  '2874',\n",
      " ...\n",
      " 'V8542', '45184', 'V2652',  '2409',  '1124',  '7801', '43401', '78009',\n",
      " '44029', '34989']\n",
      "Length: 844, dtype: str\n",
      "<StringArray>\n",
      "['25013',  '3371',  '5849',  '5780', 'V5867', '25063',  '5363',  '4580',\n",
      " '25043', '40390',\n",
      " ...\n",
      " '82534', 'V6889', 'E9238', '74921',  '9063', '72672', '37882', '38832',\n",
      " '40400', '44382']\n",
      "Length: 6973, dtype: str\n",
      "Index(['SUBJECT_ID', 'HADM_ID', 'ADMITTIME', 'DISCHTIME', 'DEATHTIME',\n",
      "       'ADMISSION_TYPE', 'ADMISSION_LOCATION', 'DISCHARGE_LOCATION',\n",
      "       'INSURANCE', 'LANGUAGE', 'RELIGION', 'MARITAL_STATUS', 'ETHNICITY',\n",
      "       'EDREGTIME', 'EDOUTTIME', 'DIAGNOSIS (LABEL)', 'HOSPITAL_EXPIRE_FLAG',\n",
      "       'HAS_CHARTEVENTS_DATA', 'DIAGNOSIS (ICD_9)', 'PROCEDURE TYPE'],\n",
      "      dtype='str')\n",
      "Index(['SUBJECT_ID', 'HADM_ID', 'ADMITTIME', 'DISCHTIME', 'DEATHTIME',\n",
      "       'ADMISSION_TYPE', 'ADMISSION_LOCATION', 'DISCHARGE_LOCATION',\n",
      "       'INSURANCE', 'LANGUAGE', 'RELIGION', 'MARITAL_STATUS', 'ETHNICITY',\n",
      "       'EDREGTIME', 'EDOUTTIME', 'DIAGNOSIS (LABEL)', 'HOSPITAL_EXPIRE_FLAG',\n",
      "       'HAS_CHARTEVENTS_DATA', 'DIAGNOSIS (ICD_9)', 'PROCEDURE TYPE'],\n",
      "      dtype='str')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nThomas's Note Retained Below:\\n\\nWe need to add another Column having a hospital amdission ID value for each event further back from the event.\\n\\nNOTE that we need to label the most recent event as 0 and count backwards in order to have all patients match.\\n\\nNeed to search in the literature what to do with repeated lab values. For example, if a patient across multiple admissions has their SpO2 value taken 6 times, what do we do with those values? For example, take average? Take most recent? Not sure\\n\\nSearch lab events that are important for the diagnoses and use those.\\n\\nAlso need to randomly sample from the non patient cohort rather than take them all.\\n\\n\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display unique ICD9 codes in the filtered patient admissions\n",
    "print(PATIENT_ADMISSIONS_MERGED['DIAGNOSIS (ICD_9)'].explode().unique())\n",
    "print(CONTROL_ADMISSIONS_MERGED['DIAGNOSIS (ICD_9)'].explode().unique())\n",
    "\n",
    "print(PATIENT_ADMISSIONS_MERGED.columns)\n",
    "print(CONTROL_ADMISSIONS_MERGED.columns)\n",
    "\n",
    "#for i in range(len(PATIENT_ADMISSIONS_MERGED['DIAGNOSIS (ICD_9)'].explode().unique())):\n",
    "#    print(str(PATIENT_ADMISSIONS_MERGED['DIAGNOSIS (ICD_9)'].explode().unique()[i]) + \",\")\n",
    "\n",
    "#for i in range(len(CONTROL_ADMISSIONS_MERGED['DIAGNOSIS (ICD_9)'].explode().unique())):\n",
    "#    print(str(CONTROL_ADMISSIONS_MERGED['DIAGNOSIS (ICD_9)'].explode().unique()[i]) + \",\")\n",
    "\n",
    "'''\n",
    "Thomas's Note Retained Below:\n",
    "\n",
    "We need to add another Column having a hospital amdission ID value for each event further back from the event.\n",
    "\n",
    "NOTE that we need to label the most recent event as 0 and count backwards in order to have all patients match.\n",
    "\n",
    "Need to search in the literature what to do with repeated lab values. For example, if a patient across multiple admissions has their SpO2 value taken 6 times, what do we do with those values? For example, take average? Take most recent? Not sure\n",
    "\n",
    "Search lab events that are important for the diagnoses and use those.\n",
    "\n",
    "Also need to randomly sample from the non patient cohort rather than take them all.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "34686fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATIENT_ADMISSIONS_MERGED.to_csv(r\"C:\\Users\\kappl\\Documents\\BIOE5860\\PATIENT_ADMISSIONS_MERGED.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
