{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8023fbe4-c3ef-4603-9a28-53b4c79cdb68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique patients with the specified ICD-9 code: 343\n"
     ]
    }
   ],
   "source": [
    "#This code compresses PROCEDURES_ICD9, and DIAGNOSES_ICD9 into single entries per admission (sorted by SEQ_NUM)\n",
    "#and merges this data with the ADMISSIONS dataframe, providing two separate dataframes with this merged structure.\n",
    "#One dataframe corresponds to patients diagnosed with specified ICD-9 codes and the other contains the control patients.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ADMISSIONS = pd.read_csv(\"./ADMISSIONS.csv\")\n",
    "DIAGNOSES_ICD = pd.read_csv(\"./DIAGNOSES_ICD.csv\")\n",
    "PATIENTS = pd.read_csv(\"./PATIENTS.csv\")\n",
    "PROCEDURES_ICD = pd.read_csv(\"./PROCEDURES_ICD.csv\")\n",
    "\n",
    "#Input ICD9 code that you want to look at here:\n",
    "my_icd9_code = [\"44100\", \"44101\", \"44102\", \"44103\"] #441 is arotic dissection. Change to 421 for bacterial endocarditis\n",
    "my_text_code = \"AORTIC DISSECTION\"\n",
    "\n",
    "# for bacertial endocarditis\n",
    "#my_icd9_code = [\"4210\", \"4211\", \"4219\"] #421 is bacterial endocarditis. Change to 441 for aortic dissection\n",
    "#my_text_code = \"BACTERIAL ENDOCARDITIS\"\n",
    "\n",
    "# for Arterial Thromboembolism\n",
    "#set my_icd9_code to be all diagnoses that start with 444\n",
    "#my_icd9_code = [4440, 4441, 44421, 44422, 44481, 44489, 4449]\n",
    "#my_text_code = \"ARTERIAL THROMBOEMBOLISM\"\n",
    "\n",
    "# for spinal abcess #324.1\n",
    "#my_icd9_code = [3241, 32410]\n",
    "#my_text_code = \"SPINAL ABSCESS\"\n",
    "\n",
    "#check what any following numbers would be in the ICD9 code\n",
    "#need to update to be 441.00, 441.01, 441.02, 441.03\n",
    "\n",
    "#Returns patients with aortic dissection\n",
    "AD_SUBJECT_ID = DIAGNOSES_ICD.loc[\n",
    "    DIAGNOSES_ICD[\"ICD9_CODE\"].astype(str).isin(my_icd9_code),\n",
    "    \"SUBJECT_ID\"\n",
    "].unique() \n",
    "\n",
    "print(f\"Number of unique patients with the specified ICD-9 code: {len(AD_SUBJECT_ID)}\")\n",
    "\n",
    "\"\"\"\n",
    "Adding filter to remove the text based AD diagnoses that don't have the ICD9 code\n",
    "\"\"\"\n",
    "\n",
    "# Also grab patients with aortic dissection in admission text\n",
    "text_ids = ADMISSIONS[\n",
    "    ADMISSIONS['DIAGNOSIS'].str.contains(my_text_code, na=False)\n",
    "]['SUBJECT_ID'].unique()\n",
    "\n",
    "# Combine both sets — these should ALL be excluded from controls\n",
    "EXCLUDE_FROM_CONTROLS = np.union1d(AD_SUBJECT_ID, text_ids)\n",
    "\n",
    "# Now build controls excluding both groups\n",
    "CONTROL_SUBJECT_ID = DIAGNOSES_ICD.loc[\n",
    "    ~DIAGNOSES_ICD[\"SUBJECT_ID\"].isin(EXCLUDE_FROM_CONTROLS),\n",
    "    \"SUBJECT_ID\"\n",
    "].unique()\n",
    "\n",
    "\"\"\"\n",
    "Done adding\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "commenting out as it's now redundant\n",
    "CONTROL_SUBJECT_ID = DIAGNOSES_ICD.loc[\n",
    "    ~DIAGNOSES_ICD[\"SUBJECT_ID\"].isin(AD_SUBJECT_ID), \n",
    "    \"SUBJECT_ID\"\n",
    "].unique()\n",
    "\"\"\"\n",
    "\n",
    "#Returns the specific admissions where aortic dissection was diagnosed\n",
    "AD_HADM_ID = DIAGNOSES_ICD.loc[\n",
    "    DIAGNOSES_ICD[\"ICD9_CODE\"].astype(str).isin(my_icd9_code),\n",
    "    \"HADM_ID\"\n",
    "].unique()\n",
    "\n",
    "\n",
    "#Identify all diagnoses for patients diagnosed with aortic dissection, including for admissions where they were not diagnosed with AD\n",
    "PATIENT_DIAGNOSES = DIAGNOSES_ICD[DIAGNOSES_ICD['SUBJECT_ID'].isin(AD_SUBJECT_ID)]\n",
    "\n",
    "CONTROL_DIAGNOSES = DIAGNOSES_ICD[DIAGNOSES_ICD['SUBJECT_ID'].isin(CONTROL_SUBJECT_ID)]\n",
    "\n",
    "#Return a new dataframe with all the ICD9 codes for each admission condensed into a single row,col val as a compressed list\n",
    "PATIENT_DIAGNOSES = (\n",
    "    PATIENT_DIAGNOSES\n",
    "    .sort_values(['HADM_ID','SEQ_NUM'])\n",
    "    .groupby(['SUBJECT_ID','HADM_ID'])['ICD9_CODE']\n",
    "    .apply(list)\n",
    "    .reset_index(name='DIAGNOSES')\n",
    ")\n",
    "\n",
    "#Return a new dataframe with all the ICD9 codes for each admission condensed into a single row,col val as a compressed list for control patients\n",
    "CONTROL_DIAGNOSES = (\n",
    "    CONTROL_DIAGNOSES\n",
    "    .sort_values(['HADM_ID','SEQ_NUM'])\n",
    "    .groupby(['SUBJECT_ID','HADM_ID'])['ICD9_CODE']\n",
    "    .apply(list)\n",
    "    .reset_index(name='DIAGNOSES')\n",
    ")\n",
    "\n",
    "#Remove DIAGNOSES_ICD to conserve memory since we have already filtered for the relevant data\n",
    "#del DIAGNOSES_ICD\n",
    "\n",
    "#Return all procedures for patients diagnosed with AD, including for admissions where they were not diagnosed with AD\n",
    "PATIENT_PROCEDURES = PROCEDURES_ICD[PROCEDURES_ICD['SUBJECT_ID'].isin(AD_SUBJECT_ID)]\n",
    "\n",
    "#identify all procedures for control patients as well\n",
    "CONTROL_PROCEDURES = PROCEDURES_ICD[PROCEDURES_ICD['SUBJECT_ID'].isin(CONTROL_SUBJECT_ID)]\n",
    "\n",
    "#Return a new dataframe with all procedure codes for each admission compressed into a single row,col val as a compressed list\n",
    "PATIENT_PROCEDURES = (\n",
    "    PATIENT_PROCEDURES\n",
    "    .sort_values(['HADM_ID','SEQ_NUM'])\n",
    "    .groupby(['SUBJECT_ID','HADM_ID'])['ICD9_CODE']\n",
    "    .apply(list)\n",
    "    .reset_index(name='PROCEDURE TYPE')\n",
    ")\n",
    "\n",
    "#Return a new dataframe with all procedure codes for each admission compressed into a single row,col val as a compressed list for control patients\n",
    "CONTROL_PROCEDURES = (\n",
    "    CONTROL_PROCEDURES\n",
    "    .sort_values(['HADM_ID','SEQ_NUM'])\n",
    "    .groupby(['SUBJECT_ID','HADM_ID'])['ICD9_CODE']\n",
    "    .apply(list)\n",
    "    .reset_index(name='PROCEDURE TYPE')\n",
    ")\n",
    "\n",
    "#Remove PROCEDURES_ICD to conserve memory since we have already extracted the relevant rows\n",
    "#del PROCEDURES_ICD\n",
    "\n",
    "#Return every admission entry for patients who were diagnosed with AD at some point\n",
    "PATIENT_ADMISSIONS = ADMISSIONS[ADMISSIONS['SUBJECT_ID'].isin(AD_SUBJECT_ID)]\n",
    "\n",
    "#pull control group admissions as well\n",
    "CONTROL_ADMISSIONS = ADMISSIONS[ADMISSIONS['SUBJECT_ID'].isin(CONTROL_SUBJECT_ID)]\n",
    "\n",
    "#Remove redundant columns from the other filtered dataframes for a cleaner merge\n",
    "PATIENT_PROCEDURES.drop('SUBJECT_ID',inplace=True,axis=1)\n",
    "PATIENT_DIAGNOSES.drop('SUBJECT_ID',inplace=True,axis=1)\n",
    "CONTROL_PROCEDURES.drop('SUBJECT_ID',inplace=True,axis=1)\n",
    "CONTROL_DIAGNOSES.drop('SUBJECT_ID',inplace=True,axis=1)\n",
    "\n",
    "#Merge the compressed DFs engineered earlier with admissions so that each admission has lab event, diagnosis, and procedure data\n",
    "PATIENT_ADMISSIONS_MERGED = PATIENT_ADMISSIONS.merge(PATIENT_DIAGNOSES, on=\"HADM_ID\", how=\"left\") \\\n",
    "            .merge(PATIENT_PROCEDURES, on=\"HADM_ID\", how=\"left\")\n",
    "\n",
    "CONTROL_ADMISSIONS_MERGED = CONTROL_ADMISSIONS.merge(CONTROL_DIAGNOSES, on=\"HADM_ID\", how=\"left\") \\\n",
    "            .merge(CONTROL_PROCEDURES, on=\"HADM_ID\", how=\"left\")\n",
    "\n",
    "#Rename columns for clarity since there is a text-based labeling column and the ICD-9 diagnosis column\n",
    "PATIENT_ADMISSIONS_MERGED = PATIENT_ADMISSIONS_MERGED.rename(columns={\"DIAGNOSIS\": \"DIAGNOSIS (LABEL)\",\"DIAGNOSES\": \"DIAGNOSIS (ICD_9)\"})\n",
    "CONTROL_ADMISSIONS_MERGED = CONTROL_ADMISSIONS_MERGED.rename(columns={\"DIAGNOSIS\": \"DIAGNOSIS (LABEL)\",\"DIAGNOSES\": \"DIAGNOSIS (ICD_9)\"})\n",
    "\n",
    "#Drop redundant row\n",
    "PATIENT_ADMISSIONS_MERGED.drop(['ROW_ID'],inplace=True,axis=1)\n",
    "CONTROL_ADMISSIONS_MERGED.drop(['ROW_ID'],inplace=True,axis=1)\n",
    "\n",
    "#Identify the admissions where AD was one of the diagnoses given to the patients, excluding admissions where AD was not diagnosed\n",
    "#No need to do this for control group\n",
    "DISEASE_ADMISSIONS = PATIENT_ADMISSIONS_MERGED[PATIENT_ADMISSIONS_MERGED['HADM_ID'].isin(AD_HADM_ID)]\n",
    "DISEASE_ADMISSIONS = DISEASE_ADMISSIONS.copy()\n",
    "\n",
    "#Convert ADMITTIME to datetime for processing\n",
    "DISEASE_ADMISSIONS['ADMITTIME'] = pd.to_datetime(DISEASE_ADMISSIONS[\"ADMITTIME\"], errors=\"coerce\")\n",
    "\n",
    "#convert to datetime for control group\n",
    "CONTROL_ADMISSIONS_MERGED['ADMITTIME'] = pd.to_datetime(CONTROL_ADMISSIONS_MERGED[\"ADMITTIME\"], errors=\"coerce\")\n",
    "\n",
    "#Sort by HADM_ID and ADMITTIME to get a sorted list for processing\n",
    "DISEASE_ADMISSIONS = DISEASE_ADMISSIONS.sort_values(['HADM_ID','ADMITTIME'])\n",
    "\n",
    "#sort control group by HADM_ID and ADMITTIME as well\n",
    "CONTROL_ADMISSIONS_MERGED = CONTROL_ADMISSIONS_MERGED.sort_values(['HADM_ID','ADMITTIME'])\n",
    "\n",
    "#Identify the earliest admission time in which patients were diagnosed with AD\n",
    "DISEASE_FIRST_ADMISSIONS = DISEASE_ADMISSIONS.groupby('SUBJECT_ID',as_index=False)['ADMITTIME'].min()\n",
    "\n",
    "#Rename this column to \"Comparator\" since it will be used for filtering admissions from after the patient was diagnosed with AD\n",
    "DISEASE_FIRST_ADMISSIONS = DISEASE_FIRST_ADMISSIONS.rename(columns={\"ADMITTIME\": \"Comparator\"})\n",
    "\n",
    "#Update ADMISSIONS_MERGED so it now contains all admissions for patients who were diagnosed with AD at some point\n",
    "#Prior and including the admission with their first diagnosis of AD. Admissions after their first diagnosis are excluded\n",
    "PATIENT_ADMISSIONS_MERGED['ADMITTIME'] = pd.to_datetime(PATIENT_ADMISSIONS_MERGED[\"ADMITTIME\"], errors=\"coerce\")\n",
    "PATIENT_ADMISSIONS_MERGED = PATIENT_ADMISSIONS_MERGED.merge(DISEASE_FIRST_ADMISSIONS,on='SUBJECT_ID',how=\"left\")\n",
    "PATIENT_ADMISSIONS_MERGED = PATIENT_ADMISSIONS_MERGED[PATIENT_ADMISSIONS_MERGED['ADMITTIME']<PATIENT_ADMISSIONS_MERGED['Comparator']]\n",
    "\n",
    "#drop the comparator column now that filtering is done so that the DFs are the same\n",
    "PATIENT_ADMISSIONS_MERGED = PATIENT_ADMISSIONS_MERGED.drop(['Comparator'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80d43a2a-8613-4a41-a37a-64dd3a6d285e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['SUBJECT_ID', 'HADM_ID', 'ADMITTIME', 'DISCHTIME', 'DEATHTIME',\n",
      "       'ADMISSION_TYPE', 'ADMISSION_LOCATION', 'DISCHARGE_LOCATION',\n",
      "       'INSURANCE', 'LANGUAGE', 'RELIGION', 'MARITAL_STATUS', 'ETHNICITY',\n",
      "       'EDREGTIME', 'EDOUTTIME', 'DIAGNOSIS (LABEL)', 'HOSPITAL_EXPIRE_FLAG',\n",
      "       'HAS_CHARTEVENTS_DATA', 'DIAGNOSIS (ICD_9)', 'PROCEDURE TYPE'],\n",
      "      dtype='str')\n",
      "(35, 20)\n",
      "Index(['SUBJECT_ID', 'HADM_ID', 'ADMITTIME', 'DISCHTIME', 'DEATHTIME',\n",
      "       'ADMISSION_TYPE', 'ADMISSION_LOCATION', 'DISCHARGE_LOCATION',\n",
      "       'INSURANCE', 'LANGUAGE', 'RELIGION', 'MARITAL_STATUS', 'ETHNICITY',\n",
      "       'EDREGTIME', 'EDOUTTIME', 'DIAGNOSIS (LABEL)', 'HOSPITAL_EXPIRE_FLAG',\n",
      "       'HAS_CHARTEVENTS_DATA', 'DIAGNOSIS (ICD_9)', 'PROCEDURE TYPE'],\n",
      "      dtype='str')\n",
      "(58440, 20)\n"
     ]
    }
   ],
   "source": [
    "#Thomas's logic retained below\n",
    "\n",
    "print(PATIENT_ADMISSIONS_MERGED.columns)\n",
    "print(PATIENT_ADMISSIONS_MERGED.shape)\n",
    "\n",
    "print(CONTROL_ADMISSIONS_MERGED.columns)\n",
    "print(CONTROL_ADMISSIONS_MERGED.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3c7abe9-6203-496b-9686-8397c5a8f263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136\n"
     ]
    }
   ],
   "source": [
    "chunksize = 50000\n",
    "LAB_EVENTS = pd.read_csv(\"./LABEVENTS.csv\",chunksize=chunksize)\n",
    "LAB_IDS = pd.read_csv(\"./Lab_Item_Codes.txt\", sep=\"\\t\")\n",
    "\n",
    "PATIENT_LAB_EVENTS2 = []\n",
    "CONTROL_LAB_EVENTS2 = []\n",
    "\n",
    "labs_of_interest = [\n",
    "    'TROPONIN', 'D-DIMER', 'CREATININE', 'BUN', \n",
    "    'UREA', 'C-REACTIVE', 'LDH', 'LACTATE DEHYDROGENASE', \n",
    "    'BILIRUBIN', 'AST', 'ALT', \n",
    "    'WHITE BLOOD', 'WBC', 'LYMPHOCYTE', 'NEUTROPHIL'\n",
    "]\n",
    "\n",
    "#create one large string which the string matcher will search through\n",
    "pattern = '|'.join(labs_of_interest)\n",
    "\n",
    "#check for any of the strings listed above in the pattern mega-string\n",
    "lab_ids = LAB_IDS[\n",
    "    LAB_IDS['Display'].str.contains(pattern, case=False, na=False)\n",
    "]\n",
    "lab_ids = lab_ids['Code']\n",
    "\n",
    "for EVENT in LAB_EVENTS:\n",
    "\n",
    "    unique_admission_count = len(EVENT['HADM_ID'].unique())\n",
    "    unique_admission_count += unique_admission_count\n",
    "\n",
    "    EVENT = EVENT.loc[\n",
    "        EVENT['ITEMID'].isin(lab_ids)\n",
    "    ]\n",
    "    \n",
    "    #Identify all patient labs for patients who were diagnosed with AD at any point. Do not include labs taken during admissions following their first diagnosis\n",
    "    PATIENT_LAB_EVENTS = EVENT[EVENT['HADM_ID'].isin(PATIENT_ADMISSIONS_MERGED['HADM_ID'])]\n",
    "    \n",
    "    #pull control group lab events as well\n",
    "    CONTROL_LAB_EVENTS = EVENT[EVENT['HADM_ID'].isin(CONTROL_ADMISSIONS_MERGED['HADM_ID'])]\n",
    "    \n",
    "    #Remove redundant rows\n",
    "    PATIENT_LAB_EVENTS = PATIENT_LAB_EVENTS.drop(['ROW_ID','VALUE'],axis=1)\n",
    "    CONTROL_LAB_EVENTS = CONTROL_LAB_EVENTS.drop(['ROW_ID','VALUE'],axis=1)\n",
    "    \n",
    "    #Convert CHARTTIME to a datetime for sorting\n",
    "    PATIENT_LAB_EVENTS['CHARTTIME'] = pd.to_datetime(PATIENT_LAB_EVENTS[\"CHARTTIME\"], errors=\"coerce\")\n",
    "    CONTROL_LAB_EVENTS['CHARTTIME'] = pd.to_datetime(CONTROL_LAB_EVENTS[\"CHARTTIME\"], errors=\"coerce\")\n",
    "    \n",
    "    #Only return values that are not na.\n",
    "    PATIENT_LAB_EVENTS = PATIENT_LAB_EVENTS[PATIENT_LAB_EVENTS['HADM_ID'].notna()]\n",
    "    CONTROL_LAB_EVENTS = CONTROL_LAB_EVENTS[CONTROL_LAB_EVENTS['HADM_ID'].notna()]\n",
    "\n",
    "    PATIENT_LAB_EVENTS2.append(PATIENT_LAB_EVENTS)\n",
    "    CONTROL_LAB_EVENTS2.append(CONTROL_LAB_EVENTS)\n",
    "    \n",
    "#Remove LAB_EVENTS to conserve lots of memory since we already have extracted the necessary data\n",
    "del LAB_EVENTS\n",
    "\n",
    "#Construct final labs DFs through concatenation\n",
    "FINAL_PATIENT_LABS = pd.concat(PATIENT_LAB_EVENTS2)\n",
    "FINAL_CONTROL_LABS = pd.concat(CONTROL_LAB_EVENTS2)\n",
    "\n",
    "print(unique_admission_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "74a02418",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_event_index_filter(PATIENT_ADMISSIONS_MERGED, CONTROL_ADMISSIONS_MERGED, AD_HADM_ID):\n",
    "\n",
    "    PATIENT_ADMISSIONS_MERGED = PATIENT_ADMISSIONS_MERGED.copy()\n",
    "    CONTROL_ADMISSIONS_MERGED = CONTROL_ADMISSIONS_MERGED.copy()\n",
    "\n",
    "    PATIENT_ADMISSIONS_MERGED[\"ADMITTIME\"] = pd.to_datetime(\n",
    "        PATIENT_ADMISSIONS_MERGED[\"ADMITTIME\"], errors=\"coerce\"\n",
    "    )\n",
    "\n",
    "    CONTROL_ADMISSIONS_MERGED[\"ADMITTIME\"] = pd.to_datetime(\n",
    "        CONTROL_ADMISSIONS_MERGED[\"ADMITTIME\"], errors=\"coerce\"\n",
    "    )\n",
    "\n",
    "    PATIENT_ADMISSIONS_MERGED = PATIENT_ADMISSIONS_MERGED.sort_values(\n",
    "        [\"SUBJECT_ID\", \"ADMITTIME\"]\n",
    "    )\n",
    "\n",
    "    \"\"\"\n",
    "    PATIENT_ADMISSIONS_MERGED[\"PATIENT_ADMISSION_INDEX\"] = (\n",
    "        PATIENT_ADMISSIONS_MERGED\n",
    "        .groupby(\"SUBJECT_ID\")\n",
    "        .cumcount() + 1\n",
    "    )\n",
    "    \"\"\"\n",
    "\n",
    "    DISEASE_ADMISSIONS = PATIENT_ADMISSIONS_MERGED[\n",
    "        PATIENT_ADMISSIONS_MERGED[\"HADM_ID\"].isin(AD_HADM_ID)\n",
    "    ].copy()\n",
    "\n",
    "    DISEASE_ADMISSIONS = DISEASE_ADMISSIONS.sort_values(\n",
    "        [\"SUBJECT_ID\", \"ADMITTIME\"]\n",
    "    )\n",
    "\n",
    "    DISEASE_FIRST_ADMISSIONS = (\n",
    "        DISEASE_ADMISSIONS\n",
    "        .groupby(\"SUBJECT_ID\", as_index=False)[\"ADMITTIME\"]\n",
    "        .min()\n",
    "        .rename(columns={\"ADMITTIME\": \"Comparator\"})\n",
    "    )\n",
    "\n",
    "    PATIENT_ADMISSIONS_MERGED = PATIENT_ADMISSIONS_MERGED.merge(\n",
    "        DISEASE_FIRST_ADMISSIONS,\n",
    "        on=\"SUBJECT_ID\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    PATIENT_ADMISSIONS_MERGED = PATIENT_ADMISSIONS_MERGED[\n",
    "        (PATIENT_ADMISSIONS_MERGED[\"Comparator\"].isna()) |\n",
    "        (PATIENT_ADMISSIONS_MERGED[\"ADMITTIME\"] <= PATIENT_ADMISSIONS_MERGED[\"Comparator\"])\n",
    "    ]\n",
    "\n",
    "    PATIENT_ADMISSIONS_MERGED.loc[PATIENT_ADMISSIONS_MERGED[\"Comparator\"].notna(), \"PATIENT_ADMISSION_INDEX\"] = (\n",
    "        PATIENT_ADMISSIONS_MERGED[PATIENT_ADMISSIONS_MERGED[\"Comparator\"].notna()]\n",
    "        .groupby(\"SUBJECT_ID\")[\"ADMITTIME\"]\n",
    "        .rank(method=\"first\", ascending=False)\n",
    "        .astype(int) - 1\n",
    "    )\n",
    "    \n",
    "    PATIENT_ADMISSIONS_MERGED[\"PATIENT_ADMISSION_INDEX\"] = PATIENT_ADMISSIONS_MERGED[\"PATIENT_ADMISSION_INDEX\"].astype(\"float\")\n",
    "\n",
    "    PATIENT_ADMISSIONS_MERGED = PATIENT_ADMISSIONS_MERGED.drop(columns=[\"Comparator\"])\n",
    "\n",
    "    # Keep control DF columns consistent\n",
    "    CONTROL_ADMISSIONS_MERGED[\"ADMISSION_INDEX_PER_PATIENT\"] = np.nan\n",
    "\n",
    "    return PATIENT_ADMISSIONS_MERGED, CONTROL_ADMISSIONS_MERGED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "944292af",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATIENT_ADMISSIONS_MERGED, CONTROL_ADMISSIONS_MERGED = apply_event_index_filter(PATIENT_ADMISSIONS_MERGED, CONTROL_ADMISSIONS_MERGED, AD_HADM_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "373a8875-2261-4d82-84ac-923810f87831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['SUBJECT_ID', 'HADM_ID', 'ADMITTIME', 'DISCHTIME', 'DEATHTIME',\n",
      "       'ADMISSION_TYPE', 'ADMISSION_LOCATION', 'DISCHARGE_LOCATION',\n",
      "       'INSURANCE', 'LANGUAGE', 'RELIGION', 'MARITAL_STATUS', 'ETHNICITY',\n",
      "       'EDREGTIME', 'EDOUTTIME', 'DIAGNOSIS (LABEL)', 'HOSPITAL_EXPIRE_FLAG',\n",
      "       'HAS_CHARTEVENTS_DATA', 'DIAGNOSIS (ICD_9)', 'PROCEDURE TYPE',\n",
      "       'PATIENT_ADMISSION_INDEX'],\n",
      "      dtype='str')\n",
      "(35, 21)\n",
      "Index(['SUBJECT_ID', 'HADM_ID', 'ADMITTIME', 'DISCHTIME', 'DEATHTIME',\n",
      "       'ADMISSION_TYPE', 'ADMISSION_LOCATION', 'DISCHARGE_LOCATION',\n",
      "       'INSURANCE', 'LANGUAGE', 'RELIGION', 'MARITAL_STATUS', 'ETHNICITY',\n",
      "       'EDREGTIME', 'EDOUTTIME', 'DIAGNOSIS (LABEL)', 'HOSPITAL_EXPIRE_FLAG',\n",
      "       'HAS_CHARTEVENTS_DATA', 'DIAGNOSIS (ICD_9)', 'PROCEDURE TYPE',\n",
      "       'ADMISSION_INDEX_PER_PATIENT'],\n",
      "      dtype='str')\n",
      "(58440, 21)\n"
     ]
    }
   ],
   "source": [
    "#display unique ICD9 codes in the filtered patient admissions\n",
    "#print(PATIENT_ADMISSIONS_MERGED['DIAGNOSIS (ICD_9)'].explode().unique())\n",
    "#print(CONTROL_ADMISSIONS_MERGED['DIAGNOSIS (ICD_9)'].explode().unique())\n",
    "\n",
    "print(PATIENT_ADMISSIONS_MERGED.columns)\n",
    "print(PATIENT_ADMISSIONS_MERGED.shape)\n",
    "print(CONTROL_ADMISSIONS_MERGED.columns)\n",
    "print(CONTROL_ADMISSIONS_MERGED.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "92392489",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATIENT_ADMISSIONS_MERGED.to_csv(r\"C:\\BIOE5860_Data\\PATIENT_ADMISSIONS_MERGED.csv\", index=False)\n",
    "CONTROL_ADMISSIONS_MERGED.to_csv(r\"C:\\BIOE5860_Data\\CONTROL_ADMISSIONS_MERGED.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3e968bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of patients with AD text but no ICD9 code remaining: 0\n",
      "Index(['SUBJECT_ID', 'HADM_ID', 'ADMITTIME', 'DISCHTIME', 'DEATHTIME',\n",
      "       'ADMISSION_TYPE', 'ADMISSION_LOCATION', 'DISCHARGE_LOCATION',\n",
      "       'INSURANCE', 'LANGUAGE', 'RELIGION', 'MARITAL_STATUS', 'ETHNICITY',\n",
      "       'EDREGTIME', 'EDOUTTIME', 'DIAGNOSIS (LABEL)', 'HOSPITAL_EXPIRE_FLAG',\n",
      "       'HAS_CHARTEVENTS_DATA', 'DIAGNOSIS (ICD_9)', 'PROCEDURE TYPE',\n",
      "       'PATIENT_ADMISSION_INDEX'],\n",
      "      dtype='str')\n",
      "(35, 21)\n",
      "Index(['SUBJECT_ID', 'HADM_ID', 'ADMITTIME', 'DISCHTIME', 'DEATHTIME',\n",
      "       'ADMISSION_TYPE', 'ADMISSION_LOCATION', 'DISCHARGE_LOCATION',\n",
      "       'INSURANCE', 'LANGUAGE', 'RELIGION', 'MARITAL_STATUS', 'ETHNICITY',\n",
      "       'EDREGTIME', 'EDOUTTIME', 'DIAGNOSIS (LABEL)', 'HOSPITAL_EXPIRE_FLAG',\n",
      "       'HAS_CHARTEVENTS_DATA', 'DIAGNOSIS (ICD_9)', 'PROCEDURE TYPE',\n",
      "       'ADMISSION_INDEX_PER_PATIENT'],\n",
      "      dtype='str')\n",
      "(58440, 21)\n"
     ]
    }
   ],
   "source": [
    "#this script finds all patients who have 'AORTIC DISSECTION' in their ADMISSIONS DIAGNOSIS text field\n",
    "#but do not have the corresponding ICD9 code in DIAGNOSES_ICD\n",
    "#my_icd9_code = [whatever yours is]\n",
    " \n",
    "aortic_ids = ADMISSIONS[ADMISSIONS['DIAGNOSIS'].str.contains('AORTIC DISSECTION', na=False)]['SUBJECT_ID'].unique()\n",
    " \n",
    "\"\"\"\n",
    "AD_SUBJECT_ID = DIAGNOSES_ICD.loc[\n",
    "    DIAGNOSES_ICD[\"ICD9_CODE\"].astype(str).isin(my_icd9_code),\n",
    "    \"SUBJECT_ID\"\n",
    "].unique()\n",
    "\"\"\"\n",
    " \n",
    "#aortic_patients = PATIENT_DIAGNOSES[PATIENT_DIAGNOSES['SUBJECT_ID']].unique()\n",
    " \n",
    "#find patients who have AORTIC DISSECTION text but don't have the ICD9 code from my_icd9_code\n",
    "\n",
    "difference = set(aortic_ids) - set(AD_SUBJECT_ID)\n",
    "reamining = len(set(difference) & set(CONTROL_SUBJECT_ID)) #if this is 0 then all were successfully removed in first cell\n",
    "print(f'Number of patients with AD text but no ICD9 code remaining: {reamining}')\n",
    "\n",
    "\n",
    "#print(len(difference))\n",
    "#print(difference)\n",
    " \n",
    "#remove all subject IDs found above from CONTROL_SUBJECT_ID since we don't know if they are actually controls \n",
    "#or if they are patients with AD who just don't have the correct ICD9 code in the DIAGNOSES_ICD file\n",
    "#CONTROL_SUBJECT_ID = CONTROL_SUBJECT_ID[~np.isin(CONTROL_SUBJECT_ID, list(difference))]\n",
    "\n",
    "#PATIENT_ADMISSIONS_MERGED.to_csv(r\"C:\\BIOE5860_Data\\PATIENT_ADMISSIONS_MERGED.csv\", index=False)\n",
    "#CONTROL_ADMISSIONS_MERGED.to_csv(r\"C:\\BIOE5860_Data\\CONTROL_ADMISSIONS_MERGED.csv\", index=False)\n",
    "\n",
    "print(PATIENT_ADMISSIONS_MERGED.columns)\n",
    "print(PATIENT_ADMISSIONS_MERGED.shape)\n",
    "print(CONTROL_ADMISSIONS_MERGED.columns)\n",
    "print(CONTROL_ADMISSIONS_MERGED.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "28fed8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient admissions: 35\n",
      "Control admissions: 58440\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "MIN_FREQ = 10  # Minimum frequency threshold for one-hot encoding\n",
    "\n",
    "\"\"\"\n",
    "NOTE, do we want this minimum frequency? It's there for dimensionality reduction/memory but\n",
    "we may want to keep more items for the sake of model performance and then do dimensionality reduction later if needed.\n",
    "We can also look at the distribution of features and decide on a case by case basis if we want to exclude certain ones based on frequency.\n",
    "\"\"\"\n",
    "\n",
    "# Tag each group\n",
    "PATIENT_ADMISSIONS_MERGED['LABEL'] = 1\n",
    "CONTROL_ADMISSIONS_MERGED['LABEL'] = 0\n",
    "\n",
    "def safe_parse_list(val):\n",
    "    \"\"\"Safely parse a list stored as string or return as-is if already a list.\"\"\"\n",
    "    if isinstance(val, list):\n",
    "        return val\n",
    "    if isinstance(val, str):\n",
    "        try:\n",
    "            return ast.literal_eval(val)\n",
    "        except (ValueError, SyntaxError):\n",
    "            return []\n",
    "    return []\n",
    "\n",
    "# Ensure datetime\n",
    "PATIENT_ADMISSIONS_MERGED['ADMITTIME'] = pd.to_datetime(\n",
    "    PATIENT_ADMISSIONS_MERGED['ADMITTIME'], errors='coerce'\n",
    ")\n",
    "CONTROL_ADMISSIONS_MERGED['ADMITTIME'] = pd.to_datetime(\n",
    "    CONTROL_ADMISSIONS_MERGED['ADMITTIME'], errors='coerce'\n",
    ")\n",
    "\n",
    "# Parse list columns\n",
    "for df in [PATIENT_ADMISSIONS_MERGED, CONTROL_ADMISSIONS_MERGED]:\n",
    "    df['DIAG_LIST'] = df['DIAGNOSIS (ICD_9)'].apply(safe_parse_list).apply(\n",
    "        lambda codes: [str(c).strip() for c in codes]\n",
    "    )\n",
    "    df['PROC_LIST'] = df['PROCEDURE TYPE'].apply(safe_parse_list).apply(\n",
    "        lambda codes: [str(c).strip() for c in codes]\n",
    "    )\n",
    "\n",
    "# For controls, assign an admission index (reverse chronological, same logic as patients)\n",
    "# so that index 0 = their most recent admission\n",
    "CONTROL_ADMISSIONS_MERGED = CONTROL_ADMISSIONS_MERGED.sort_values(\n",
    "    ['SUBJECT_ID', 'ADMITTIME']\n",
    ")\n",
    "CONTROL_ADMISSIONS_MERGED['PATIENT_ADMISSION_INDEX'] = (\n",
    "    CONTROL_ADMISSIONS_MERGED\n",
    "    .groupby('SUBJECT_ID')['ADMITTIME']\n",
    "    .rank(method='first', ascending=False)\n",
    "    .astype(int) - 1\n",
    ")\n",
    "\n",
    "print(f\"Patient admissions: {PATIENT_ADMISSIONS_MERGED.shape[0]}\")\n",
    "print(f\"Control admissions: {CONTROL_ADMISSIONS_MERGED.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e50e98a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique patients with more than one admission: 5\n"
     ]
    }
   ],
   "source": [
    "# Calculate how many unique subjects in the patient group has more than one admission overall\n",
    "patient_admission_counts = PATIENT_ADMISSIONS_MERGED.groupby('SUBJECT_ID').size()\n",
    "patients_with_multiple_admissions = patient_admission_counts[patient_admission_counts > 1].count()\n",
    "print(f\"Number of unique patients with more than one admission: {patients_with_multiple_admissions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "49bcc376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building temporal diagnosis properties for patients...\n",
      "Building temporal diagnosis properties for controls...\n",
      "Building temporal procedure properties for patients...\n",
      "Building temporal procedure properties for controls...\n"
     ]
    }
   ],
   "source": [
    "def build_temporal_code_properties(df, code_col, prefix):\n",
    "    \"\"\"\n",
    "    For each patient, build:\n",
    "      - {prefix}_{code}_ever: 1 if code appears in any admission\n",
    "      - {prefix}_{code}_at_dx: 1 if code appears at index 0 (diagnosis/reference admission)\n",
    "      - {prefix}_{code}_first_idx: earliest admission index where code appeared (0 = diagnosis admission, higher = further back)\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for subj, grp in df.groupby('SUBJECT_ID'):\n",
    "        ever_codes = set()\n",
    "        at_dx_codes = set()\n",
    "        first_idx = {}\n",
    "\n",
    "        for _, admission in grp.iterrows():\n",
    "            idx = admission['PATIENT_ADMISSION_INDEX']\n",
    "            codes = admission[code_col]\n",
    "\n",
    "            for c in codes:\n",
    "                ever_codes.add(c)\n",
    "                if idx == 0:\n",
    "                    at_dx_codes.add(c)\n",
    "                # Track the highest index (furthest back) where code first appeared\n",
    "                if c not in first_idx or idx > first_idx[c]:\n",
    "                    first_idx[c] = idx\n",
    "\n",
    "        rows.append({\n",
    "            'SUBJECT_ID': subj,\n",
    "            '_ever': ever_codes,\n",
    "            '_at_dx': at_dx_codes,\n",
    "            '_first_idx': first_idx\n",
    "        })\n",
    "\n",
    "    return rows\n",
    "\n",
    "# Remove AD diagnosis codes from the list of codes we are building properties for\n",
    "# since those are the reference point and we want to look at other codes in relation to that\n",
    "# Remove target-leaking codes — these ARE the diagnosis we're predicting\n",
    "LEAK_DIAG_CODES = my_icd9_code\n",
    "\n",
    "for df in [PATIENT_ADMISSIONS_MERGED, CONTROL_ADMISSIONS_MERGED]:\n",
    "    df['DIAG_LIST'] = df['DIAG_LIST'].apply(\n",
    "        lambda codes: [c for c in codes if c not in LEAK_DIAG_CODES]\n",
    "    )\n",
    "\n",
    "# Now build temporal properties for diagnoses and procedures\n",
    "print(\"Building temporal diagnosis properties for patients...\")\n",
    "patient_diag_rows = build_temporal_code_properties(\n",
    "    PATIENT_ADMISSIONS_MERGED, 'DIAG_LIST', 'DIAG'\n",
    ")\n",
    "\n",
    "print(\"Building temporal diagnosis properties for controls...\")\n",
    "control_diag_rows = build_temporal_code_properties(\n",
    "    CONTROL_ADMISSIONS_MERGED, 'DIAG_LIST', 'DIAG'\n",
    ")\n",
    "\n",
    "print(\"Building temporal procedure properties for patients...\")\n",
    "patient_proc_rows = build_temporal_code_properties(\n",
    "    PATIENT_ADMISSIONS_MERGED, 'PROC_LIST', 'PROC'\n",
    ")\n",
    "\n",
    "print(\"Building temporal procedure properties for controls...\")\n",
    "control_proc_rows = build_temporal_code_properties(\n",
    "    CONTROL_ADMISSIONS_MERGED, 'PROC_LIST', 'PROC'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929f3830",
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporal_rows_to_df(rows, prefix):\n",
    "    \"\"\"Convert the temporal dicts (diagnoses/procedures/labs) into a wide dataframe.\"\"\"\n",
    "    records = []\n",
    "    for r in rows:\n",
    "        rec = {'SUBJECT_ID': r['SUBJECT_ID']}\n",
    "        for c in r['_ever']:\n",
    "            rec[f'{prefix}_{c}_ever'] = 1\n",
    "        for c in r['_at_dx']:\n",
    "            rec[f'{prefix}_{c}_at_dx'] = 1\n",
    "        for c, idx in r['_first_idx'].items():\n",
    "            rec[f'{prefix}_{c}_first_idx'] = idx\n",
    "        records.append(rec)\n",
    "\n",
    "    df = pd.DataFrame(records).set_index('SUBJECT_ID')\n",
    "\n",
    "    # Fill NaN for _ever and _at_dx columns with 0\n",
    "    ever_cols = [c for c in df.columns if c.endswith('_ever')]\n",
    "    at_dx_cols = [c for c in df.columns if c.endswith('_at_dx')]\n",
    "    df[ever_cols] = df[ever_cols].fillna(0).astype(int)\n",
    "    df[at_dx_cols] = df[at_dx_cols].fillna(0).astype(int)\n",
    "\n",
    "    # _first_idx stays NaN if the code was never seen (will be filled later)\n",
    "    return df\n",
    "\n",
    "# Build diagnosis DFs\n",
    "patient_diag_df = temporal_rows_to_df(patient_diag_rows, 'DIAG')\n",
    "control_diag_df = temporal_rows_to_df(control_diag_rows, 'DIAG')\n",
    "\n",
    "# Build procedure DFs\n",
    "patient_proc_df = temporal_rows_to_df(patient_proc_rows, 'PROC')\n",
    "control_proc_df = temporal_rows_to_df(control_proc_rows, 'PROC')\n",
    "\n",
    "# Display some stats about the resulting dataframes\n",
    "n_patients = len(patient_diag_df)\n",
    "n_controls = len(control_diag_df)\n",
    "control_subjects_all = control_diag_df.index.values\n",
    "\n",
    "print(f\"Patient subjects: {n_patients}\")\n",
    "print(f\"Control subjects (all): {n_controls}\")\n",
    "print(f\"Imbalance ratio: 1:{n_controls // n_patients}\")\n",
    "\n",
    "# Combine patient + control for diagnoses\n",
    "diag_combined = pd.concat([patient_diag_df, control_diag_df], axis=0).fillna(0)\n",
    "\n",
    "# Combine patient + control for procedures\n",
    "proc_combined = pd.concat([patient_proc_df, control_proc_df], axis=0).fillna(0)\n",
    "\n",
    "# Apply frequency filter to _ever columns (overall code frequency)\n",
    "diag_ever_cols = [c for c in diag_combined.columns if c.endswith('_ever')]\n",
    "diag_freq = diag_combined[diag_ever_cols].sum(axis=0)\n",
    "frequent_diag_codes = [c.replace('_ever', '') for c in diag_ever_cols if diag_freq[c] >= MIN_FREQ]\n",
    "\n",
    "# Keep only columns for frequent codes with all 3 types (_ever, _at_dx, _first_idx)\n",
    "diag_keep = []\n",
    "for code_prefix in frequent_diag_codes:\n",
    "    for suffix in ['_ever', '_at_dx', '_first_idx']:\n",
    "        col = f\"{code_prefix}{suffix}\"\n",
    "        if col in diag_combined.columns:\n",
    "            diag_keep.append(col)\n",
    "diag_combined = diag_combined[diag_keep]\n",
    "\n",
    "# Same for procedures\n",
    "proc_ever_cols = [c for c in proc_combined.columns if c.endswith('_ever')]\n",
    "proc_freq = proc_combined[proc_ever_cols].sum(axis=0)\n",
    "frequent_proc_codes = [c.replace('_ever', '') for c in proc_ever_cols if proc_freq[c] >= MIN_FREQ]\n",
    "\n",
    "proc_keep = []\n",
    "for code_prefix in frequent_proc_codes:\n",
    "    for suffix in ['_ever', '_at_dx', '_first_idx']:\n",
    "        col = f\"{code_prefix}{suffix}\"\n",
    "        if col in proc_combined.columns:\n",
    "            proc_keep.append(col)\n",
    "proc_combined = proc_combined[proc_keep]\n",
    "\n",
    "print(f\"Diagnosis items (3 per code, freq >= {MIN_FREQ}): {diag_combined.shape[1]}\")\n",
    "print(f\"Procedure items (3 per code, freq >= {MIN_FREQ}): {proc_combined.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbf0e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build a demographics reference from the admissions data (one row per patient)\n",
    "def get_demographics(df):\n",
    "    \"\"\"Pull demographics from the most recent admission (index 0).\"\"\"\n",
    "    idx0 = df[df['PATIENT_ADMISSION_INDEX'] == 0].copy()\n",
    "    if len(idx0) == 0:\n",
    "        idx0 = df.sort_values('ADMITTIME', ascending=False).head(1).copy()\n",
    "    return idx0.iloc[0]\n",
    "\n",
    "patient_demo = (\n",
    "    PATIENT_ADMISSIONS_MERGED\n",
    "    .groupby('SUBJECT_ID')\n",
    "    .apply(get_demographics)\n",
    "    [['INSURANCE', 'ETHNICITY', 'MARITAL_STATUS']]\n",
    ")\n",
    "\n",
    "control_demo = (\n",
    "    CONTROL_ADMISSIONS_MERGED\n",
    "    .groupby('SUBJECT_ID')\n",
    "    .apply(get_demographics)\n",
    "    [['INSURANCE', 'ETHNICITY', 'MARITAL_STATUS']]\n",
    ")\n",
    "\n",
    "# Admission type properties ie did patient ever have each type?\n",
    "def get_admission_types(df):\n",
    "    return df.groupby('SUBJECT_ID')['ADMISSION_TYPE'].apply(\n",
    "        lambda x: list(x.unique())\n",
    "    )\n",
    "\n",
    "patient_admit_types = get_admission_types(PATIENT_ADMISSIONS_MERGED)\n",
    "control_admit_types = get_admission_types(CONTROL_ADMISSIONS_MERGED)\n",
    "\n",
    "# Number of admissions per patient\n",
    "patient_num_admits = PATIENT_ADMISSIONS_MERGED.groupby('SUBJECT_ID')['HADM_ID'].nunique()\n",
    "control_num_admits = (\n",
    "    CONTROL_ADMISSIONS_MERGED\n",
    "    .groupby('SUBJECT_ID')['HADM_ID'].nunique()\n",
    ")\n",
    "\n",
    "# Hospital expire flag (max across admissions)\n",
    "patient_expire = PATIENT_ADMISSIONS_MERGED.groupby('SUBJECT_ID')['HOSPITAL_EXPIRE_FLAG'].max()\n",
    "control_expire = (\n",
    "    CONTROL_ADMISSIONS_MERGED\n",
    "    .groupby('SUBJECT_ID')['HOSPITAL_EXPIRE_FLAG'].max()\n",
    ")\n",
    "\n",
    "# Combine demographics\n",
    "demo_combined = pd.concat([patient_demo, control_demo], axis=0)\n",
    "demo_combined = demo_combined.fillna('UNKNOWN')\n",
    "\n",
    "# One-hot encode categorical demographics\n",
    "demo_onehot = pd.get_dummies(demo_combined, prefix_sep='_', dtype=int)\n",
    "\n",
    "# One-hot encode admission types\n",
    "admit_types_all = pd.concat([patient_admit_types, control_admit_types])\n",
    "mlb_admit = MultiLabelBinarizer()\n",
    "admit_encoded = mlb_admit.fit_transform(admit_types_all)\n",
    "admit_cols = [f\"ADMTYPE_{c}\" for c in mlb_admit.classes_]\n",
    "admit_df = pd.DataFrame(admit_encoded, columns=admit_cols, index=admit_types_all.index)\n",
    "\n",
    "# Add numeric information about number of admissions and hospital expire flag\n",
    "num_admits_all = pd.concat([patient_num_admits, control_num_admits]).rename('NUM_ADMISSIONS')\n",
    "expire_all = pd.concat([patient_expire, control_expire]).rename('HOSPITAL_EXPIRE_FLAG')\n",
    "\n",
    "demo_final = demo_onehot.join(admit_df).join(num_admits_all).join(expire_all)\n",
    "\n",
    "# Filter rare categories\n",
    "demo_final = demo_final.loc[:, demo_final.sum(axis=0) >= MIN_FREQ]\n",
    "\n",
    "print(f\"Demographic items: {demo_final.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6044b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_LABS = pd.concat([FINAL_PATIENT_LABS, FINAL_CONTROL_LABS], ignore_index=True)\n",
    "\n",
    "# Build HADM_ID -> SUBJECT_ID mapping from both admission tables\n",
    "hadm_to_subject = {}\n",
    "for _, row in PATIENT_ADMISSIONS_MERGED[['HADM_ID', 'SUBJECT_ID']].iterrows():\n",
    "    hadm_to_subject[row['HADM_ID']] = row['SUBJECT_ID']\n",
    "for _, row in CONTROL_ADMISSIONS_MERGED[['HADM_ID', 'SUBJECT_ID']].iterrows():\n",
    "    hadm_to_subject[row['HADM_ID']] = row['SUBJECT_ID']\n",
    "\n",
    "# Build HADM_ID -> PATIENT_ADMISSION_INDEX mapping\n",
    "hadm_to_idx = {}\n",
    "for _, row in PATIENT_ADMISSIONS_MERGED[['HADM_ID', 'PATIENT_ADMISSION_INDEX']].iterrows():\n",
    "    hadm_to_idx[row['HADM_ID']] = row['PATIENT_ADMISSION_INDEX']\n",
    "for _, row in CONTROL_ADMISSIONS_MERGED[['HADM_ID', 'PATIENT_ADMISSION_INDEX']].iterrows():\n",
    "    hadm_to_idx[row['HADM_ID']] = row['PATIENT_ADMISSION_INDEX']\n",
    "\n",
    "ALL_LABS['SUBJECT_ID_MAPPED'] = ALL_LABS['HADM_ID'].map(hadm_to_subject)\n",
    "ALL_LABS['ADMISSION_INDEX'] = ALL_LABS['HADM_ID'].map(hadm_to_idx)\n",
    "\n",
    "# Keep only labs for subjects in our combined set\n",
    "all_subjects = set(diag_combined.index)\n",
    "ALL_LABS = ALL_LABS[ALL_LABS['SUBJECT_ID_MAPPED'].isin(all_subjects)]\n",
    "\n",
    "ALL_LABS['VALUENUM'] = pd.to_numeric(ALL_LABS['VALUENUM'], errors='coerce')\n",
    "ALL_LABS = ALL_LABS.dropna(subset=['VALUENUM'])\n",
    "\n",
    "print(f\"Total lab rows after filtering: {len(ALL_LABS)}\")\n",
    "\n",
    "# Overall aggregation (across all admissions)\n",
    "lab_overall = ALL_LABS.groupby(['SUBJECT_ID_MAPPED', 'ITEMID'])['VALUENUM'].agg(\n",
    "    ['mean', 'min', 'max']\n",
    ").reset_index()\n",
    "\n",
    "ALL_LABS_sorted = ALL_LABS.sort_values(['SUBJECT_ID_MAPPED', 'ITEMID', 'CHARTTIME'])\n",
    "lab_last = (\n",
    "    ALL_LABS_sorted\n",
    "    .groupby(['SUBJECT_ID_MAPPED', 'ITEMID'])['VALUENUM']\n",
    "    .last()\n",
    "    .reset_index()\n",
    ")\n",
    "lab_last.columns = ['SUBJECT_ID_MAPPED', 'ITEMID', 'last']\n",
    "\n",
    "lab_overall = lab_overall.merge(lab_last, on=['SUBJECT_ID_MAPPED', 'ITEMID'], how='left')\n",
    "\n",
    "lab_overall_pivot = lab_overall.pivot_table(\n",
    "    index='SUBJECT_ID_MAPPED',\n",
    "    columns='ITEMID',\n",
    "    values=['mean', 'min', 'max', 'last']\n",
    ")\n",
    "lab_overall_pivot.columns = [f\"LAB_{int(item)}_{stat}\" for stat, item in lab_overall_pivot.columns]\n",
    "\n",
    "# Index-0 specific labs (values at the diagnosis/reference admission)\n",
    "labs_at_dx = ALL_LABS[ALL_LABS['ADMISSION_INDEX'] == 0].copy()\n",
    "\n",
    "lab_dx_agg = labs_at_dx.groupby(['SUBJECT_ID_MAPPED', 'ITEMID'])['VALUENUM'].agg(\n",
    "    ['mean', 'min', 'max']\n",
    ").reset_index()\n",
    "\n",
    "labs_at_dx_sorted = labs_at_dx.sort_values(['SUBJECT_ID_MAPPED', 'ITEMID', 'CHARTTIME'])\n",
    "lab_dx_last = (\n",
    "    labs_at_dx_sorted\n",
    "    .groupby(['SUBJECT_ID_MAPPED', 'ITEMID'])['VALUENUM']\n",
    "    .last()\n",
    "    .reset_index()\n",
    ")\n",
    "lab_dx_last.columns = ['SUBJECT_ID_MAPPED', 'ITEMID', 'last']\n",
    "\n",
    "lab_dx_agg = lab_dx_agg.merge(lab_dx_last, on=['SUBJECT_ID_MAPPED', 'ITEMID'], how='left')\n",
    "\n",
    "lab_dx_pivot = lab_dx_agg.pivot_table(\n",
    "    index='SUBJECT_ID_MAPPED',\n",
    "    columns='ITEMID',\n",
    "    values=['mean', 'min', 'max', 'last']\n",
    ")\n",
    "lab_dx_pivot.columns = [f\"LAB_{int(item)}_dx_{stat}\" for stat, item in lab_dx_pivot.columns]\n",
    "\n",
    "# Deltas: index-0 mean minus overall mean\n",
    "# This captures how abnormal a patient's labs were at presentation compared to their own historical baseline\n",
    "\n",
    "# Get overall mean per (patient, lab)\n",
    "overall_mean = lab_overall[['SUBJECT_ID_MAPPED', 'ITEMID', 'mean']].copy()\n",
    "overall_mean.columns = ['SUBJECT_ID_MAPPED', 'ITEMID', 'overall_mean']\n",
    "\n",
    "# Get index-0 mean per (patient, lab)\n",
    "dx_mean = lab_dx_agg[['SUBJECT_ID_MAPPED', 'ITEMID', 'mean']].copy()\n",
    "dx_mean.columns = ['SUBJECT_ID_MAPPED', 'ITEMID', 'dx_mean']\n",
    "\n",
    "# Merge and compute delta\n",
    "delta = overall_mean.merge(dx_mean, on=['SUBJECT_ID_MAPPED', 'ITEMID'], how='inner')\n",
    "delta['delta'] = delta['dx_mean'] - delta['overall_mean']\n",
    "\n",
    "# Pivot to wide format\n",
    "delta_pivot = delta.pivot_table(\n",
    "    index='SUBJECT_ID_MAPPED',\n",
    "    columns='ITEMID',\n",
    "    values='delta'\n",
    ")\n",
    "delta_pivot.columns = [f\"LAB_{int(item)}_delta\" for item in delta_pivot.columns]\n",
    "\n",
    "# Merge overall + dx-specific + delta labs\n",
    "lab_all = lab_overall_pivot.join(lab_dx_pivot, how='outer').join(delta_pivot, how='outer')\n",
    "lab_all.index.name = 'SUBJECT_ID'\n",
    "\n",
    "print(f\"Labs (overall + at-diagnosis + delta): {lab_all.shape[1]}\")\n",
    "print(f\"  Overall: {lab_overall_pivot.shape[1]}\")\n",
    "print(f\"  At-diagnosis: {lab_dx_pivot.shape[1]}\")\n",
    "print(f\"  Delta: {delta_pivot.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967d2f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create label series\n",
    "patient_labels = pd.Series(1, index=patient_diag_df.index, name='LABEL')\n",
    "control_labels = pd.Series(0, index=control_diag_df.index, name='LABEL')\n",
    "labels = pd.concat([patient_labels, control_labels])\n",
    "\n",
    "# Join everything on SUBJECT_ID index\n",
    "final_matrix = pd.DataFrame(labels)\n",
    "final_matrix = final_matrix.join(diag_combined, how='left')\n",
    "final_matrix = final_matrix.join(proc_combined, how='left')\n",
    "final_matrix = final_matrix.join(demo_final, how='left')\n",
    "final_matrix = final_matrix.join(lab_all, how='left')\n",
    "\n",
    "# Reset index so SUBJECT_ID becomes a column\n",
    "final_matrix = final_matrix.reset_index().rename(columns={'index': 'SUBJECT_ID'})\n",
    "\n",
    "print(f\"Final matrix shape: {final_matrix.shape}\")\n",
    "print(f\"  Diagnoses: {diag_combined.shape[1]}\")\n",
    "print(f\"  Procedures: {proc_combined.shape[1]}\")\n",
    "print(f\"  Demographics: {demo_final.shape[1]}\")\n",
    "print(f\"  Labs: {lab_all.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ec67f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find number of missing values per column\n",
    "missing_values = final_matrix.isnull().sum()\n",
    "print(\"Missing values per column:\")\n",
    "print(missing_values[missing_values > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c8a3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify columns (everything except SUBJECT_ID and LABEL)\n",
    "final_cols = [c for c in final_matrix.columns if c not in ['SUBJECT_ID', 'LABEL']]\n",
    "\n",
    "# Separate numeric types for imputation\n",
    "# _first_idx and lab columns are numeric so impute with median\n",
    "# _ever, _at_dx, and one-hot columns are binary so fill with 0\n",
    "binary_cols = [c for c in final_cols if c.endswith('_ever') or c.endswith('_at_dx')\n",
    "               or c.startswith('ADMTYPE_') or c.startswith('INSURANCE_')\n",
    "               or c.startswith('ETHNICITY_') or c.startswith('MARITAL_STATUS_')]\n",
    "\n",
    "idx_cols = [c for c in final_cols if c.endswith('_first_idx')]\n",
    "\n",
    "lab_cols = [c for c in final_cols if c.startswith('LAB_')]\n",
    "\n",
    "numeric_cols = ['NUM_ADMISSIONS', 'HOSPITAL_EXPIRE_FLAG']\n",
    "\n",
    "# Fill binary columns with 0\n",
    "final_matrix[binary_cols] = final_matrix[binary_cols].fillna(0).astype(int)\n",
    "\n",
    "# Fill _first_idx with -1 (code never seen)\n",
    "final_matrix[idx_cols] = final_matrix[idx_cols].fillna(-1)\n",
    "\n",
    "# Fill numeric columns with 0\n",
    "for c in numeric_cols:\n",
    "    if c in final_matrix.columns:\n",
    "        final_matrix[c] = final_matrix[c].fillna(0)\n",
    "\n",
    "# Impute lab columns with median\n",
    "if lab_cols:\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    final_matrix[lab_cols] = imputer.fit_transform(final_matrix[lab_cols])\n",
    "\n",
    "# Verify no NaNs remain\n",
    "nan_count = final_matrix[final_cols].isna().sum().sum()\n",
    "print(f\"Remaining NaN's: {nan_count}\")\n",
    "\n",
    "# Save\n",
    "#final_matrix.to_csv(r\"C:\\BIOE5860_Data\\MODEL_READY_MATRIX.csv\", index=False)\n",
    "final_matrix.to_parquet(\"./MODEL_READY_MATRIX.parquet\", index=False)\n",
    "\n",
    "print(f\"\\nSaved MODEL_READY_MATRIX.parquet\")\n",
    "print(f\"  Rows: {final_matrix.shape[0]}\")\n",
    "print(f\"  Columns: {final_matrix.shape[1]}\")\n",
    "print(f\"  Label=1 (AD): {(final_matrix['LABEL']==1).sum()}\")\n",
    "print(f\"  Label=0 (Control): {(final_matrix['LABEL']==0).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555f5353",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Final matrix columns:\")\n",
    "for i, col in enumerate(final_matrix.columns.tolist()):\n",
    "    print(f\"  {i}: {col}\")\n",
    "print(f\"\\nTotal: {len(final_cols)}\")\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "final_matrix.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
