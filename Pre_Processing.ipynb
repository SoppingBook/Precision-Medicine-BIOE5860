{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8023fbe4-c3ef-4603-9a28-53b4c79cdb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code compresses PROCEDURES_ICD9, and DIAGNOSES_ICD9 into single entries per admission (sorted by SEQ_NUM)\n",
    "#and merges this data with the ADMISSIONS dataframe, providing two separate dataframes with this merged structure.\n",
    "#One dataframe corresponds to patients diagnosed with specified ICD-9 codes and the other contains the control patients.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ADMISSIONS = pd.read_csv(r\"C:\\BIOE5860_Data\\ADMISSIONS.csv\")\n",
    "DIAGNOSES_ICD = pd.read_csv(r\"C:\\BIOE5860_Data\\DIAGNOSES_ICD.csv\")\n",
    "PATIENTS = pd.read_csv(r\"C:\\BIOE5860_Data\\PATIENTS.csv\")\n",
    "PROCEDURES_ICD = pd.read_csv(r\"C:\\BIOE5860_Data\\PROCEDURES_ICD.csv\")\n",
    "\n",
    "#Input ICD9 code that you want to look at here:\n",
    "my_icd9_code = [\"44100\", \"44101\", \"44102\", \"44103\"] #441 is arotic dissection. Change to 421 for bacterial endocarditis\n",
    "#check what any following numbers would be in the ICD9 code\n",
    "#need to update to be 441.00, 441.01, 441.02, 441.03\n",
    "\n",
    "#Returns patients with aortic dissection\n",
    "AD_SUBJECT_ID = DIAGNOSES_ICD.loc[\n",
    "    DIAGNOSES_ICD[\"ICD9_CODE\"].astype(str).isin(my_icd9_code),\n",
    "    \"SUBJECT_ID\"\n",
    "].unique() \n",
    "\n",
    "\"\"\"\n",
    "Adding filter to remove the text based AD diagnoses that don't have the ICD9 code\n",
    "\"\"\"\n",
    "\n",
    "# Also grab patients with aortic dissection in admission text\n",
    "aortic_text_ids = ADMISSIONS[\n",
    "    ADMISSIONS['DIAGNOSIS'].str.contains('AORTIC DISSECTION', na=False)\n",
    "]['SUBJECT_ID'].unique()\n",
    "\n",
    "# Combine both sets â€” these should ALL be excluded from controls\n",
    "EXCLUDE_FROM_CONTROLS = np.union1d(AD_SUBJECT_ID, aortic_text_ids)\n",
    "\n",
    "# Now build controls excluding both groups\n",
    "CONTROL_SUBJECT_ID = DIAGNOSES_ICD.loc[\n",
    "    ~DIAGNOSES_ICD[\"SUBJECT_ID\"].isin(EXCLUDE_FROM_CONTROLS),\n",
    "    \"SUBJECT_ID\"\n",
    "].unique()\n",
    "\n",
    "\"\"\"\n",
    "Done adding\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "commenting out as it's now redundant\n",
    "CONTROL_SUBJECT_ID = DIAGNOSES_ICD.loc[\n",
    "    ~DIAGNOSES_ICD[\"SUBJECT_ID\"].isin(AD_SUBJECT_ID), \n",
    "    \"SUBJECT_ID\"\n",
    "].unique()\n",
    "\"\"\"\n",
    "\n",
    "#Returns the specific admissions where aortic dissection was diagnosed\n",
    "AD_HADM_ID = DIAGNOSES_ICD.loc[\n",
    "    DIAGNOSES_ICD[\"ICD9_CODE\"].astype(str).isin(my_icd9_code),\n",
    "    \"HADM_ID\"\n",
    "].unique()\n",
    "\n",
    "\n",
    "#Identify all diagnoses for patients diagnosed with aortic dissection, including for admissions where they were not diagnosed with AD\n",
    "PATIENT_DIAGNOSES = DIAGNOSES_ICD[DIAGNOSES_ICD['SUBJECT_ID'].isin(AD_SUBJECT_ID)]\n",
    "\n",
    "CONTROL_DIAGNOSES = DIAGNOSES_ICD[DIAGNOSES_ICD['SUBJECT_ID'].isin(CONTROL_SUBJECT_ID)]\n",
    "\n",
    "#Return a new dataframe with all the ICD9 codes for each admission condensed into a single row,col val as a compressed list\n",
    "PATIENT_DIAGNOSES = (\n",
    "    PATIENT_DIAGNOSES\n",
    "    .sort_values(['HADM_ID','SEQ_NUM'])\n",
    "    .groupby(['SUBJECT_ID','HADM_ID'])['ICD9_CODE']\n",
    "    .apply(list)\n",
    "    .reset_index(name='DIAGNOSES')\n",
    ")\n",
    "\n",
    "#Return a new dataframe with all the ICD9 codes for each admission condensed into a single row,col val as a compressed list for control patients\n",
    "CONTROL_DIAGNOSES = (\n",
    "    CONTROL_DIAGNOSES\n",
    "    .sort_values(['HADM_ID','SEQ_NUM'])\n",
    "    .groupby(['SUBJECT_ID','HADM_ID'])['ICD9_CODE']\n",
    "    .apply(list)\n",
    "    .reset_index(name='DIAGNOSES')\n",
    ")\n",
    "\n",
    "#Remove DIAGNOSES_ICD to conserve memory since we have already filtered for the relevant data\n",
    "#del DIAGNOSES_ICD\n",
    "\n",
    "#Return all procedures for patients diagnosed with AD, including for admissions where they were not diagnosed with AD\n",
    "PATIENT_PROCEDURES = PROCEDURES_ICD[PROCEDURES_ICD['SUBJECT_ID'].isin(AD_SUBJECT_ID)]\n",
    "\n",
    "#identify all procedures for control patients as well\n",
    "CONTROL_PROCEDURES = PROCEDURES_ICD[PROCEDURES_ICD['SUBJECT_ID'].isin(CONTROL_SUBJECT_ID)]\n",
    "\n",
    "#Return a new dataframe with all procedure codes for each admission compressed into a single row,col val as a compressed list\n",
    "PATIENT_PROCEDURES = (\n",
    "    PATIENT_PROCEDURES\n",
    "    .sort_values(['HADM_ID','SEQ_NUM'])\n",
    "    .groupby(['SUBJECT_ID','HADM_ID'])['ICD9_CODE']\n",
    "    .apply(list)\n",
    "    .reset_index(name='PROCEDURE TYPE')\n",
    ")\n",
    "\n",
    "#Return a new dataframe with all procedure codes for each admission compressed into a single row,col val as a compressed list for control patients\n",
    "CONTROL_PROCEDURES = (\n",
    "    CONTROL_PROCEDURES\n",
    "    .sort_values(['HADM_ID','SEQ_NUM'])\n",
    "    .groupby(['SUBJECT_ID','HADM_ID'])['ICD9_CODE']\n",
    "    .apply(list)\n",
    "    .reset_index(name='PROCEDURE TYPE')\n",
    ")\n",
    "\n",
    "#Remove PROCEDURES_ICD to conserve memory since we have already extracted the relevant rows\n",
    "#del PROCEDURES_ICD\n",
    "\n",
    "#Return every admission entry for patients who were diagnosed with AD at some point\n",
    "PATIENT_ADMISSIONS = ADMISSIONS[ADMISSIONS['SUBJECT_ID'].isin(AD_SUBJECT_ID)]\n",
    "\n",
    "#pull control group admissions as well\n",
    "CONTROL_ADMISSIONS = ADMISSIONS[ADMISSIONS['SUBJECT_ID'].isin(CONTROL_SUBJECT_ID)]\n",
    "\n",
    "#Remove redundant columns from the other filtered dataframes for a cleaner merge\n",
    "PATIENT_PROCEDURES.drop('SUBJECT_ID',inplace=True,axis=1)\n",
    "PATIENT_DIAGNOSES.drop('SUBJECT_ID',inplace=True,axis=1)\n",
    "CONTROL_PROCEDURES.drop('SUBJECT_ID',inplace=True,axis=1)\n",
    "CONTROL_DIAGNOSES.drop('SUBJECT_ID',inplace=True,axis=1)\n",
    "\n",
    "#Merge the compressed DFs engineered earlier with admissions so that each admission has lab event, diagnosis, and procedure data\n",
    "PATIENT_ADMISSIONS_MERGED = PATIENT_ADMISSIONS.merge(PATIENT_DIAGNOSES, on=\"HADM_ID\", how=\"left\") \\\n",
    "            .merge(PATIENT_PROCEDURES, on=\"HADM_ID\", how=\"left\")\n",
    "\n",
    "CONTROL_ADMISSIONS_MERGED = CONTROL_ADMISSIONS.merge(CONTROL_DIAGNOSES, on=\"HADM_ID\", how=\"left\") \\\n",
    "            .merge(CONTROL_PROCEDURES, on=\"HADM_ID\", how=\"left\")\n",
    "\n",
    "#Rename columns for clarity since there is a text-based labeling column and the ICD-9 diagnosis column\n",
    "PATIENT_ADMISSIONS_MERGED = PATIENT_ADMISSIONS_MERGED.rename(columns={\"DIAGNOSIS\": \"DIAGNOSIS (LABEL)\",\"DIAGNOSES\": \"DIAGNOSIS (ICD_9)\"})\n",
    "CONTROL_ADMISSIONS_MERGED = CONTROL_ADMISSIONS_MERGED.rename(columns={\"DIAGNOSIS\": \"DIAGNOSIS (LABEL)\",\"DIAGNOSES\": \"DIAGNOSIS (ICD_9)\"})\n",
    "\n",
    "#Drop redundant row\n",
    "PATIENT_ADMISSIONS_MERGED.drop(['ROW_ID'],inplace=True,axis=1)\n",
    "CONTROL_ADMISSIONS_MERGED.drop(['ROW_ID'],inplace=True,axis=1)\n",
    "\n",
    "#Identify the admissions where AD was one of the diagnoses given to the patients, excluding admissions where AD was not diagnosed\n",
    "#No need to do this for control group\n",
    "DISEASE_ADMISSIONS = PATIENT_ADMISSIONS_MERGED[PATIENT_ADMISSIONS_MERGED['HADM_ID'].isin(AD_HADM_ID)]\n",
    "DISEASE_ADMISSIONS = DISEASE_ADMISSIONS.copy()\n",
    "\n",
    "#Convert ADMITTIME to datetime for processing\n",
    "DISEASE_ADMISSIONS['ADMITTIME'] = pd.to_datetime(DISEASE_ADMISSIONS[\"ADMITTIME\"], errors=\"coerce\")\n",
    "\n",
    "#convert to datetime for control group\n",
    "CONTROL_ADMISSIONS_MERGED['ADMITTIME'] = pd.to_datetime(CONTROL_ADMISSIONS_MERGED[\"ADMITTIME\"], errors=\"coerce\")\n",
    "\n",
    "#Sort by HADM_ID and ADMITTIME to get a sorted list for processing\n",
    "DISEASE_ADMISSIONS = DISEASE_ADMISSIONS.sort_values(['HADM_ID','ADMITTIME'])\n",
    "\n",
    "#sort control group by HADM_ID and ADMITTIME as well\n",
    "CONTROL_ADMISSIONS_MERGED = CONTROL_ADMISSIONS_MERGED.sort_values(['HADM_ID','ADMITTIME'])\n",
    "\n",
    "#Identify the earliest admission time in which patients were diagnosed with AD\n",
    "DISEASE_FIRST_ADMISSIONS = DISEASE_ADMISSIONS.groupby('SUBJECT_ID',as_index=False)['ADMITTIME'].min()\n",
    "\n",
    "#Rename this column to \"Comparator\" since it will be used for filtering admissions from after the patient was diagnosed with AD\n",
    "DISEASE_FIRST_ADMISSIONS = DISEASE_FIRST_ADMISSIONS.rename(columns={\"ADMITTIME\": \"Comparator\"})\n",
    "\n",
    "#Update ADMISSIONS_MERGED so it now contains all admissions for patients who were diagnosed with AD at some point\n",
    "#Prior and including the admission with their first diagnosis of AD. Admissions after their first diagnosis are excluded\n",
    "PATIENT_ADMISSIONS_MERGED['ADMITTIME'] = pd.to_datetime(PATIENT_ADMISSIONS_MERGED[\"ADMITTIME\"], errors=\"coerce\")\n",
    "PATIENT_ADMISSIONS_MERGED = PATIENT_ADMISSIONS_MERGED.merge(DISEASE_FIRST_ADMISSIONS,on='SUBJECT_ID',how=\"left\")\n",
    "PATIENT_ADMISSIONS_MERGED = PATIENT_ADMISSIONS_MERGED[PATIENT_ADMISSIONS_MERGED['ADMITTIME']<=PATIENT_ADMISSIONS_MERGED['Comparator']]\n",
    "\n",
    "#drop the comparator column now that filtering is done so that the DFs are the same\n",
    "PATIENT_ADMISSIONS_MERGED = PATIENT_ADMISSIONS_MERGED.drop(['Comparator'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80d43a2a-8613-4a41-a37a-64dd3a6d285e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['SUBJECT_ID', 'HADM_ID', 'ADMITTIME', 'DISCHTIME', 'DEATHTIME',\n",
      "       'ADMISSION_TYPE', 'ADMISSION_LOCATION', 'DISCHARGE_LOCATION',\n",
      "       'INSURANCE', 'LANGUAGE', 'RELIGION', 'MARITAL_STATUS', 'ETHNICITY',\n",
      "       'EDREGTIME', 'EDOUTTIME', 'DIAGNOSIS (LABEL)', 'HOSPITAL_EXPIRE_FLAG',\n",
      "       'HAS_CHARTEVENTS_DATA', 'DIAGNOSIS (ICD_9)', 'PROCEDURE TYPE'],\n",
      "      dtype='str')\n",
      "(378, 20)\n",
      "Index(['SUBJECT_ID', 'HADM_ID', 'ADMITTIME', 'DISCHTIME', 'DEATHTIME',\n",
      "       'ADMISSION_TYPE', 'ADMISSION_LOCATION', 'DISCHARGE_LOCATION',\n",
      "       'INSURANCE', 'LANGUAGE', 'RELIGION', 'MARITAL_STATUS', 'ETHNICITY',\n",
      "       'EDREGTIME', 'EDOUTTIME', 'DIAGNOSIS (LABEL)', 'HOSPITAL_EXPIRE_FLAG',\n",
      "       'HAS_CHARTEVENTS_DATA', 'DIAGNOSIS (ICD_9)', 'PROCEDURE TYPE'],\n",
      "      dtype='str')\n",
      "(58440, 20)\n"
     ]
    }
   ],
   "source": [
    "#Thomas's logic retained below\n",
    "\n",
    "print(PATIENT_ADMISSIONS_MERGED.columns)\n",
    "print(PATIENT_ADMISSIONS_MERGED.shape)\n",
    "\n",
    "print(CONTROL_ADMISSIONS_MERGED.columns)\n",
    "print(CONTROL_ADMISSIONS_MERGED.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3c7abe9-6203-496b-9686-8397c5a8f263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136\n"
     ]
    }
   ],
   "source": [
    "chunksize = 50000\n",
    "LAB_EVENTS = pd.read_csv(r\"C:\\BIOE5860_Data\\LABEVENTS.csv\",chunksize=chunksize)\n",
    "LAB_IDS = pd.read_csv(r\"C:\\BIOE5860_Data\\Lab_Item_Codes.txt\", sep=\"\\t\")\n",
    "\n",
    "PATIENT_LAB_EVENTS2 = []\n",
    "CONTROL_LAB_EVENTS2 = []\n",
    "\n",
    "labs_of_interest = [\n",
    "    'TROPONIN', 'D-DIMER', 'CREATININE', 'BUN', \n",
    "    'UREA', 'C-REACTIVE', 'LDH', 'LACTATE DEHYDROGENASE', \n",
    "    'BILIRUBIN', 'AST', 'ALT', \n",
    "    'WHITE BLOOD', 'WBC', 'LYMPHOCYTE', 'NEUTROPHIL'\n",
    "]\n",
    "\n",
    "#create one large string which the string matcher will search through\n",
    "pattern = '|'.join(labs_of_interest)\n",
    "\n",
    "#check for any of the strings listed above in the pattern mega-string\n",
    "lab_ids = LAB_IDS[\n",
    "    LAB_IDS['Display'].str.contains(pattern, case=False, na=False)\n",
    "]\n",
    "lab_ids = lab_ids['Code']\n",
    "\n",
    "for EVENT in LAB_EVENTS:\n",
    "\n",
    "    unique_admission_count = len(EVENT['HADM_ID'].unique())\n",
    "    unique_admission_count += unique_admission_count\n",
    "\n",
    "    EVENT = EVENT.loc[\n",
    "        EVENT['ITEMID'].isin(lab_ids)\n",
    "    ]\n",
    "    \n",
    "    #Identify all patient labs for patients who were diagnosed with AD at any point. Do not include labs taken during admissions following their first diagnosis\n",
    "    PATIENT_LAB_EVENTS = EVENT[EVENT['HADM_ID'].isin(PATIENT_ADMISSIONS_MERGED['HADM_ID'])]\n",
    "    \n",
    "    #pull control group lab events as well\n",
    "    CONTROL_LAB_EVENTS = EVENT[EVENT['HADM_ID'].isin(CONTROL_ADMISSIONS_MERGED['HADM_ID'])]\n",
    "    \n",
    "    #Remove redundant rows\n",
    "    PATIENT_LAB_EVENTS = PATIENT_LAB_EVENTS.drop(['ROW_ID','VALUE'],axis=1)\n",
    "    CONTROL_LAB_EVENTS = CONTROL_LAB_EVENTS.drop(['ROW_ID','VALUE'],axis=1)\n",
    "    \n",
    "    #Convert CHARTTIME to a datetime for sorting\n",
    "    PATIENT_LAB_EVENTS['CHARTTIME'] = pd.to_datetime(PATIENT_LAB_EVENTS[\"CHARTTIME\"], errors=\"coerce\")\n",
    "    CONTROL_LAB_EVENTS['CHARTTIME'] = pd.to_datetime(CONTROL_LAB_EVENTS[\"CHARTTIME\"], errors=\"coerce\")\n",
    "    \n",
    "    #Only return values that are not na.\n",
    "    PATIENT_LAB_EVENTS = PATIENT_LAB_EVENTS[PATIENT_LAB_EVENTS['HADM_ID'].notna()]\n",
    "    CONTROL_LAB_EVENTS = CONTROL_LAB_EVENTS[CONTROL_LAB_EVENTS['HADM_ID'].notna()]\n",
    "\n",
    "    PATIENT_LAB_EVENTS2.append(PATIENT_LAB_EVENTS)\n",
    "    CONTROL_LAB_EVENTS2.append(CONTROL_LAB_EVENTS)\n",
    "    \n",
    "#Remove LAB_EVENTS to conserve lots of memory since we already have extracted the necessary data\n",
    "del LAB_EVENTS\n",
    "\n",
    "#Construct final labs DFs through concatenation\n",
    "FINAL_PATIENT_LABS = pd.concat(PATIENT_LAB_EVENTS2)\n",
    "FINAL_CONTROL_LABS = pd.concat(CONTROL_LAB_EVENTS2)\n",
    "\n",
    "print(unique_admission_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74a02418",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_event_index_filter(PATIENT_ADMISSIONS_MERGED, CONTROL_ADMISSIONS_MERGED, AD_HADM_ID):\n",
    "\n",
    "    PATIENT_ADMISSIONS_MERGED = PATIENT_ADMISSIONS_MERGED.copy()\n",
    "    CONTROL_ADMISSIONS_MERGED = CONTROL_ADMISSIONS_MERGED.copy()\n",
    "\n",
    "    PATIENT_ADMISSIONS_MERGED[\"ADMITTIME\"] = pd.to_datetime(\n",
    "        PATIENT_ADMISSIONS_MERGED[\"ADMITTIME\"], errors=\"coerce\"\n",
    "    )\n",
    "\n",
    "    CONTROL_ADMISSIONS_MERGED[\"ADMITTIME\"] = pd.to_datetime(\n",
    "        CONTROL_ADMISSIONS_MERGED[\"ADMITTIME\"], errors=\"coerce\"\n",
    "    )\n",
    "\n",
    "    PATIENT_ADMISSIONS_MERGED = PATIENT_ADMISSIONS_MERGED.sort_values(\n",
    "        [\"SUBJECT_ID\", \"ADMITTIME\"]\n",
    "    )\n",
    "\n",
    "    \"\"\"\n",
    "    PATIENT_ADMISSIONS_MERGED[\"PATIENT_ADMISSION_INDEX\"] = (\n",
    "        PATIENT_ADMISSIONS_MERGED\n",
    "        .groupby(\"SUBJECT_ID\")\n",
    "        .cumcount() + 1\n",
    "    )\n",
    "    \"\"\"\n",
    "\n",
    "    DISEASE_ADMISSIONS = PATIENT_ADMISSIONS_MERGED[\n",
    "        PATIENT_ADMISSIONS_MERGED[\"HADM_ID\"].isin(AD_HADM_ID)\n",
    "    ].copy()\n",
    "\n",
    "    DISEASE_ADMISSIONS = DISEASE_ADMISSIONS.sort_values(\n",
    "        [\"SUBJECT_ID\", \"ADMITTIME\"]\n",
    "    )\n",
    "\n",
    "    DISEASE_FIRST_ADMISSIONS = (\n",
    "        DISEASE_ADMISSIONS\n",
    "        .groupby(\"SUBJECT_ID\", as_index=False)[\"ADMITTIME\"]\n",
    "        .min()\n",
    "        .rename(columns={\"ADMITTIME\": \"Comparator\"})\n",
    "    )\n",
    "\n",
    "    PATIENT_ADMISSIONS_MERGED = PATIENT_ADMISSIONS_MERGED.merge(\n",
    "        DISEASE_FIRST_ADMISSIONS,\n",
    "        on=\"SUBJECT_ID\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    PATIENT_ADMISSIONS_MERGED = PATIENT_ADMISSIONS_MERGED[\n",
    "        (PATIENT_ADMISSIONS_MERGED[\"Comparator\"].isna()) |\n",
    "        (PATIENT_ADMISSIONS_MERGED[\"ADMITTIME\"] <= PATIENT_ADMISSIONS_MERGED[\"Comparator\"])\n",
    "    ]\n",
    "\n",
    "    PATIENT_ADMISSIONS_MERGED.loc[PATIENT_ADMISSIONS_MERGED[\"Comparator\"].notna(), \"PATIENT_ADMISSION_INDEX\"] = (\n",
    "        PATIENT_ADMISSIONS_MERGED[PATIENT_ADMISSIONS_MERGED[\"Comparator\"].notna()]\n",
    "        .groupby(\"SUBJECT_ID\")[\"ADMITTIME\"]\n",
    "        .rank(method=\"first\", ascending=False)\n",
    "        .astype(int) - 1\n",
    "    )\n",
    "    \n",
    "    PATIENT_ADMISSIONS_MERGED[\"PATIENT_ADMISSION_INDEX\"] = PATIENT_ADMISSIONS_MERGED[\"PATIENT_ADMISSION_INDEX\"].astype(\"float\")\n",
    "\n",
    "    PATIENT_ADMISSIONS_MERGED = PATIENT_ADMISSIONS_MERGED.drop(columns=[\"Comparator\"])\n",
    "\n",
    "    # Keep control DF columns consistent\n",
    "    CONTROL_ADMISSIONS_MERGED[\"ADMISSION_INDEX_PER_PATIENT\"] = np.nan\n",
    "\n",
    "    return PATIENT_ADMISSIONS_MERGED, CONTROL_ADMISSIONS_MERGED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "944292af",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATIENT_ADMISSIONS_MERGED, CONTROL_ADMISSIONS_MERGED = apply_event_index_filter(PATIENT_ADMISSIONS_MERGED, CONTROL_ADMISSIONS_MERGED, AD_HADM_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "373a8875-2261-4d82-84ac-923810f87831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['SUBJECT_ID', 'HADM_ID', 'ADMITTIME', 'DISCHTIME', 'DEATHTIME',\n",
      "       'ADMISSION_TYPE', 'ADMISSION_LOCATION', 'DISCHARGE_LOCATION',\n",
      "       'INSURANCE', 'LANGUAGE', 'RELIGION', 'MARITAL_STATUS', 'ETHNICITY',\n",
      "       'EDREGTIME', 'EDOUTTIME', 'DIAGNOSIS (LABEL)', 'HOSPITAL_EXPIRE_FLAG',\n",
      "       'HAS_CHARTEVENTS_DATA', 'DIAGNOSIS (ICD_9)', 'PROCEDURE TYPE',\n",
      "       'PATIENT_ADMISSION_INDEX'],\n",
      "      dtype='str')\n",
      "(378, 21)\n",
      "Index(['SUBJECT_ID', 'HADM_ID', 'ADMITTIME', 'DISCHTIME', 'DEATHTIME',\n",
      "       'ADMISSION_TYPE', 'ADMISSION_LOCATION', 'DISCHARGE_LOCATION',\n",
      "       'INSURANCE', 'LANGUAGE', 'RELIGION', 'MARITAL_STATUS', 'ETHNICITY',\n",
      "       'EDREGTIME', 'EDOUTTIME', 'DIAGNOSIS (LABEL)', 'HOSPITAL_EXPIRE_FLAG',\n",
      "       'HAS_CHARTEVENTS_DATA', 'DIAGNOSIS (ICD_9)', 'PROCEDURE TYPE',\n",
      "       'ADMISSION_INDEX_PER_PATIENT'],\n",
      "      dtype='str')\n",
      "(58440, 21)\n"
     ]
    }
   ],
   "source": [
    "#display unique ICD9 codes in the filtered patient admissions\n",
    "#print(PATIENT_ADMISSIONS_MERGED['DIAGNOSIS (ICD_9)'].explode().unique())\n",
    "#print(CONTROL_ADMISSIONS_MERGED['DIAGNOSIS (ICD_9)'].explode().unique())\n",
    "\n",
    "print(PATIENT_ADMISSIONS_MERGED.columns)\n",
    "print(PATIENT_ADMISSIONS_MERGED.shape)\n",
    "print(CONTROL_ADMISSIONS_MERGED.columns)\n",
    "print(CONTROL_ADMISSIONS_MERGED.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92392489",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATIENT_ADMISSIONS_MERGED.to_csv(r\"C:\\BIOE5860_Data\\PATIENT_ADMISSIONS_MERGED.csv\", index=False)\n",
    "CONTROL_ADMISSIONS_MERGED.to_csv(r\"C:\\BIOE5860_Data\\CONTROL_ADMISSIONS_MERGED.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e968bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "17\n",
      "{np.int64(83040), np.int64(56898), np.int64(41603), np.int64(26308), np.int64(25828), np.int64(5353), np.int64(682), np.int64(19914), np.int64(24652), np.int64(48078), np.int64(31377), np.int64(16181), np.int64(21206), np.int64(95030), np.int64(13208), np.int64(6938), np.int64(5183)}\n",
      "Index(['SUBJECT_ID', 'HADM_ID', 'ADMITTIME', 'DISCHTIME', 'DEATHTIME',\n",
      "       'ADMISSION_TYPE', 'ADMISSION_LOCATION', 'DISCHARGE_LOCATION',\n",
      "       'INSURANCE', 'LANGUAGE', 'RELIGION', 'MARITAL_STATUS', 'ETHNICITY',\n",
      "       'EDREGTIME', 'EDOUTTIME', 'DIAGNOSIS (LABEL)', 'HOSPITAL_EXPIRE_FLAG',\n",
      "       'HAS_CHARTEVENTS_DATA', 'DIAGNOSIS (ICD_9)', 'PROCEDURE TYPE',\n",
      "       'PATIENT_ADMISSION_INDEX'],\n",
      "      dtype='str')\n",
      "(378, 21)\n",
      "Index(['SUBJECT_ID', 'HADM_ID', 'ADMITTIME', 'DISCHTIME', 'DEATHTIME',\n",
      "       'ADMISSION_TYPE', 'ADMISSION_LOCATION', 'DISCHARGE_LOCATION',\n",
      "       'INSURANCE', 'LANGUAGE', 'RELIGION', 'MARITAL_STATUS', 'ETHNICITY',\n",
      "       'EDREGTIME', 'EDOUTTIME', 'DIAGNOSIS (LABEL)', 'HOSPITAL_EXPIRE_FLAG',\n",
      "       'HAS_CHARTEVENTS_DATA', 'DIAGNOSIS (ICD_9)', 'PROCEDURE TYPE',\n",
      "       'ADMISSION_INDEX_PER_PATIENT'],\n",
      "      dtype='str')\n",
      "(58440, 21)\n"
     ]
    }
   ],
   "source": [
    "#this script finds all patients who have 'AORTIC DISSECTION' in their ADMISSIONS DIAGNOSIS text field\n",
    "#but do not have the corresponding ICD9 code in DIAGNOSES_ICD\n",
    "#my_icd9_code = [whatever yours is]\n",
    " \n",
    "aortic_ids = ADMISSIONS[ADMISSIONS['DIAGNOSIS'].str.contains('AORTIC DISSECTION', na=False)]['SUBJECT_ID'].unique()\n",
    " \n",
    "\"\"\"\n",
    "AD_SUBJECT_ID = DIAGNOSES_ICD.loc[\n",
    "    DIAGNOSES_ICD[\"ICD9_CODE\"].astype(str).isin(my_icd9_code),\n",
    "    \"SUBJECT_ID\"\n",
    "].unique()\n",
    "\"\"\"\n",
    " \n",
    "#aortic_patients = PATIENT_DIAGNOSES[PATIENT_DIAGNOSES['SUBJECT_ID']].unique()\n",
    " \n",
    "#find patients who have AORTIC DISSECTION text but don't have the ICD9 code from my_icd9_code\n",
    "\n",
    "difference = set(aortic_ids) - set(AD_SUBJECT_ID)\n",
    "print(len(set(difference) & set(CONTROL_SUBJECT_ID))) #if this is 0 then all were successfully removed in first cell\n",
    "\n",
    "print(len(difference))\n",
    "print(difference)\n",
    " \n",
    "#remove all subject IDs found above from CONTROL_SUBJECT_ID since we don't know if they are actually controls \n",
    "#or if they are patients with AD who just don't have the correct ICD9 code in the DIAGNOSES_ICD file\n",
    "#CONTROL_SUBJECT_ID = CONTROL_SUBJECT_ID[~np.isin(CONTROL_SUBJECT_ID, list(difference))]\n",
    "\n",
    "#PATIENT_ADMISSIONS_MERGED.to_csv(r\"C:\\BIOE5860_Data\\PATIENT_ADMISSIONS_MERGED.csv\", index=False)\n",
    "#CONTROL_ADMISSIONS_MERGED.to_csv(r\"C:\\BIOE5860_Data\\CONTROL_ADMISSIONS_MERGED.csv\", index=False)\n",
    "\n",
    "print(PATIENT_ADMISSIONS_MERGED.columns)\n",
    "print(PATIENT_ADMISSIONS_MERGED.shape)\n",
    "print(CONTROL_ADMISSIONS_MERGED.columns)\n",
    "print(CONTROL_ADMISSIONS_MERGED.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
