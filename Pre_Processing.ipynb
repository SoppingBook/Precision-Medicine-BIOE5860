{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8023fbe4-c3ef-4603-9a28-53b4c79cdb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code compresses PROCEDURES_ICD9, and DIAGNOSES_ICD9 into single entries per admission (sorted by SEQ_NUM)\n",
    "#and merges this data with the ADMISSIONS dataframe, providing two separate dataframes with this merged structure.\n",
    "#One dataframe corresponds to patients diagnosed with specified ICD-9 codes and the other contains the control patients.\n",
    "\n",
    "#Updates made:\n",
    "# 1. Separated lab events from the merged dataframes into separate dataframes to support easier unpacking later.\n",
    "# 2. Fixed logic for pulling SUBJECT_ID for controls patients to prevent leakage of diseased patients into controls DF\n",
    "# 3. Used chunking while processing the large LABEVENTS CSV to prevent memory overload and crashes\n",
    "# 4. Specified labs specific to aortic dissection and pulled corresponding ITEMNAMES from Lab_Item_Codes.txt.\n",
    "#    Only patients with these labs exist in the controls LABEVENTS DF and the diseased patients LABEVENTS DF\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ADMISSIONS = pd.read_csv(r\"C:\\BIOE5860_Data\\ADMISSIONS.csv\")\n",
    "DIAGNOSES_ICD = pd.read_csv(r\"C:\\BIOE5860_Data\\DIAGNOSES_ICD.csv\")\n",
    "PATIENTS = pd.read_csv(r\"C:\\BIOE5860_Data\\PATIENTS.csv\")\n",
    "PROCEDURES_ICD = pd.read_csv(r\"C:\\BIOE5860_Data\\PROCEDURES_ICD.csv\")\n",
    "\n",
    "#Input ICD9 code that you want to look at here:\n",
    "my_icd9_code = [\"44100\", \"44101\", \"44102\", \"44103\"] #441 is arotic dissection. Change to 421 for bacterial endocarditis\n",
    "#check what any following numbers would be in the ICD9 code\n",
    "#need to update to be 441.00, 441.01, 441.02, 441.03\n",
    "\n",
    "#Returns patients with aortic dissection\n",
    "AD_SUBJECT_ID = DIAGNOSES_ICD.loc[\n",
    "    DIAGNOSES_ICD[\"ICD9_CODE\"].astype(str).isin(my_icd9_code),\n",
    "    \"SUBJECT_ID\"\n",
    "].unique() \n",
    "\n",
    "\"\"\"\n",
    "Adding filter to remove the text based AD diagnoses that don't have the ICD9 code\n",
    "\"\"\"\n",
    "\n",
    "# Also grab patients with aortic dissection in admission text\n",
    "aortic_text_ids = ADMISSIONS[\n",
    "    ADMISSIONS['DIAGNOSIS'].str.contains('AORTIC DISSECTION', na=False)\n",
    "]['SUBJECT_ID'].unique()\n",
    "\n",
    "# Combine both sets â€” these should ALL be excluded from controls\n",
    "EXCLUDE_FROM_CONTROLS = np.union1d(AD_SUBJECT_ID, aortic_text_ids)\n",
    "\n",
    "# Now build controls excluding both groups\n",
    "CONTROL_SUBJECT_ID = DIAGNOSES_ICD.loc[\n",
    "    ~DIAGNOSES_ICD[\"SUBJECT_ID\"].isin(EXCLUDE_FROM_CONTROLS),\n",
    "    \"SUBJECT_ID\"\n",
    "].unique()\n",
    "\n",
    "\"\"\"\n",
    "Done adding\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "commenting out as it's now redundant\n",
    "CONTROL_SUBJECT_ID = DIAGNOSES_ICD.loc[\n",
    "    ~DIAGNOSES_ICD[\"SUBJECT_ID\"].isin(AD_SUBJECT_ID), \n",
    "    \"SUBJECT_ID\"\n",
    "].unique()\n",
    "\"\"\"\n",
    "\n",
    "#Returns the specific admissions where aortic dissection was diagnosed\n",
    "AD_HADM_ID = DIAGNOSES_ICD.loc[\n",
    "    DIAGNOSES_ICD[\"ICD9_CODE\"].astype(str).isin(my_icd9_code),\n",
    "    \"HADM_ID\"\n",
    "].unique()\n",
    "\n",
    "\n",
    "#Identify all diagnoses for patients diagnosed with aortic dissection, including for admissions where they were not diagnosed with AD\n",
    "PATIENT_DIAGNOSES = DIAGNOSES_ICD[DIAGNOSES_ICD['SUBJECT_ID'].isin(AD_SUBJECT_ID)]\n",
    "\n",
    "CONTROL_DIAGNOSES = DIAGNOSES_ICD[DIAGNOSES_ICD['SUBJECT_ID'].isin(CONTROL_SUBJECT_ID)]\n",
    "\n",
    "#Return a new dataframe with all the ICD9 codes for each admission condensed into a single row,col val as a compressed list\n",
    "PATIENT_DIAGNOSES = (\n",
    "    PATIENT_DIAGNOSES\n",
    "    .sort_values(['HADM_ID','SEQ_NUM'])\n",
    "    .groupby(['SUBJECT_ID','HADM_ID'])['ICD9_CODE']\n",
    "    .apply(list)\n",
    "    .reset_index(name='DIAGNOSES')\n",
    ")\n",
    "\n",
    "#Return a new dataframe with all the ICD9 codes for each admission condensed into a single row,col val as a compressed list for control patients\n",
    "CONTROL_DIAGNOSES = (\n",
    "    CONTROL_DIAGNOSES\n",
    "    .sort_values(['HADM_ID','SEQ_NUM'])\n",
    "    .groupby(['SUBJECT_ID','HADM_ID'])['ICD9_CODE']\n",
    "    .apply(list)\n",
    "    .reset_index(name='DIAGNOSES')\n",
    ")\n",
    "\n",
    "#Remove DIAGNOSES_ICD to conserve memory since we have already filtered for the relevant data\n",
    "#del DIAGNOSES_ICD\n",
    "\n",
    "#Return all procedures for patients diagnosed with AD, including for admissions where they were not diagnosed with AD\n",
    "PATIENT_PROCEDURES = PROCEDURES_ICD[PROCEDURES_ICD['SUBJECT_ID'].isin(AD_SUBJECT_ID)]\n",
    "\n",
    "#identify all procedures for control patients as well\n",
    "CONTROL_PROCEDURES = PROCEDURES_ICD[PROCEDURES_ICD['SUBJECT_ID'].isin(CONTROL_SUBJECT_ID)]\n",
    "\n",
    "#Return a new dataframe with all procedure codes for each admission compressed into a single row,col val as a compressed list\n",
    "PATIENT_PROCEDURES = (\n",
    "    PATIENT_PROCEDURES\n",
    "    .sort_values(['HADM_ID','SEQ_NUM'])\n",
    "    .groupby(['SUBJECT_ID','HADM_ID'])['ICD9_CODE']\n",
    "    .apply(list)\n",
    "    .reset_index(name='PROCEDURE TYPE')\n",
    ")\n",
    "\n",
    "#Return a new dataframe with all procedure codes for each admission compressed into a single row,col val as a compressed list for control patients\n",
    "CONTROL_PROCEDURES = (\n",
    "    CONTROL_PROCEDURES\n",
    "    .sort_values(['HADM_ID','SEQ_NUM'])\n",
    "    .groupby(['SUBJECT_ID','HADM_ID'])['ICD9_CODE']\n",
    "    .apply(list)\n",
    "    .reset_index(name='PROCEDURE TYPE')\n",
    ")\n",
    "\n",
    "#Remove PROCEDURES_ICD to conserve memory since we have already extracted the relevant rows\n",
    "#del PROCEDURES_ICD\n",
    "\n",
    "#Return every admission entry for patients who were diagnosed with AD at some point\n",
    "PATIENT_ADMISSIONS = ADMISSIONS[ADMISSIONS['SUBJECT_ID'].isin(AD_SUBJECT_ID)]\n",
    "\n",
    "#pull control group admissions as well\n",
    "CONTROL_ADMISSIONS = ADMISSIONS[ADMISSIONS['SUBJECT_ID'].isin(CONTROL_SUBJECT_ID)]\n",
    "\n",
    "#Remove redundant columns from the other filtered dataframes for a cleaner merge\n",
    "PATIENT_PROCEDURES.drop('SUBJECT_ID',inplace=True,axis=1)\n",
    "PATIENT_DIAGNOSES.drop('SUBJECT_ID',inplace=True,axis=1)\n",
    "CONTROL_PROCEDURES.drop('SUBJECT_ID',inplace=True,axis=1)\n",
    "CONTROL_DIAGNOSES.drop('SUBJECT_ID',inplace=True,axis=1)\n",
    "\n",
    "#Merge the compressed DFs engineered earlier with admissions so that each admission has lab event, diagnosis, and procedure data\n",
    "PATIENT_ADMISSIONS_MERGED = PATIENT_ADMISSIONS.merge(PATIENT_DIAGNOSES, on=\"HADM_ID\", how=\"left\") \\\n",
    "            .merge(PATIENT_PROCEDURES, on=\"HADM_ID\", how=\"left\")\n",
    "\n",
    "CONTROL_ADMISSIONS_MERGED = CONTROL_ADMISSIONS.merge(CONTROL_DIAGNOSES, on=\"HADM_ID\", how=\"left\") \\\n",
    "            .merge(CONTROL_PROCEDURES, on=\"HADM_ID\", how=\"left\")\n",
    "\n",
    "#Rename columns for clarity since there is a text-based labeling column and the ICD-9 diagnosis column\n",
    "PATIENT_ADMISSIONS_MERGED = PATIENT_ADMISSIONS_MERGED.rename(columns={\"DIAGNOSIS\": \"DIAGNOSIS (LABEL)\",\"DIAGNOSES\": \"DIAGNOSIS (ICD_9)\"})\n",
    "CONTROL_ADMISSIONS_MERGED = CONTROL_ADMISSIONS_MERGED.rename(columns={\"DIAGNOSIS\": \"DIAGNOSIS (LABEL)\",\"DIAGNOSES\": \"DIAGNOSIS (ICD_9)\"})\n",
    "\n",
    "#Drop redundant row\n",
    "PATIENT_ADMISSIONS_MERGED.drop(['ROW_ID'],inplace=True,axis=1)\n",
    "CONTROL_ADMISSIONS_MERGED.drop(['ROW_ID'],inplace=True,axis=1)\n",
    "\n",
    "#Identify the admissions where AD was one of the diagnoses given to the patients, excluding admissions where AD was not diagnosed\n",
    "#No need to do this for control group\n",
    "DISEASE_ADMISSIONS = PATIENT_ADMISSIONS_MERGED[PATIENT_ADMISSIONS_MERGED['HADM_ID'].isin(AD_HADM_ID)]\n",
    "DISEASE_ADMISSIONS = DISEASE_ADMISSIONS.copy()\n",
    "\n",
    "#Convert ADMITTIME to datetime for processing\n",
    "DISEASE_ADMISSIONS['ADMITTIME'] = pd.to_datetime(DISEASE_ADMISSIONS[\"ADMITTIME\"], errors=\"coerce\")\n",
    "\n",
    "#convert to datetime for control group\n",
    "CONTROL_ADMISSIONS_MERGED['ADMITTIME'] = pd.to_datetime(CONTROL_ADMISSIONS_MERGED[\"ADMITTIME\"], errors=\"coerce\")\n",
    "\n",
    "#Sort by HADM_ID and ADMITTIME to get a sorted list for processing\n",
    "DISEASE_ADMISSIONS = DISEASE_ADMISSIONS.sort_values(['HADM_ID','ADMITTIME'])\n",
    "\n",
    "#sort control group by HADM_ID and ADMITTIME as well\n",
    "CONTROL_ADMISSIONS_MERGED = CONTROL_ADMISSIONS_MERGED.sort_values(['HADM_ID','ADMITTIME'])\n",
    "\n",
    "#Identify the earliest admission time in which patients were diagnosed with AD\n",
    "DISEASE_FIRST_ADMISSIONS = DISEASE_ADMISSIONS.groupby('SUBJECT_ID',as_index=False)['ADMITTIME'].min()\n",
    "\n",
    "#Rename this column to \"Comparator\" since it will be used for filtering admissions from after the patient was diagnosed with AD\n",
    "DISEASE_FIRST_ADMISSIONS = DISEASE_FIRST_ADMISSIONS.rename(columns={\"ADMITTIME\": \"Comparator\"})\n",
    "\n",
    "#Update ADMISSIONS_MERGED so it now contains all admissions for patients who were diagnosed with AD at some point\n",
    "#Prior and including the admission with their first diagnosis of AD. Admissions after their first diagnosis are excluded\n",
    "PATIENT_ADMISSIONS_MERGED['ADMITTIME'] = pd.to_datetime(PATIENT_ADMISSIONS_MERGED[\"ADMITTIME\"], errors=\"coerce\")\n",
    "PATIENT_ADMISSIONS_MERGED = PATIENT_ADMISSIONS_MERGED.merge(DISEASE_FIRST_ADMISSIONS,on='SUBJECT_ID',how=\"left\")\n",
    "PATIENT_ADMISSIONS_MERGED = PATIENT_ADMISSIONS_MERGED[PATIENT_ADMISSIONS_MERGED['ADMITTIME']<=PATIENT_ADMISSIONS_MERGED['Comparator']]\n",
    "\n",
    "#drop the comparator column now that filtering is done so that the DFs are the same\n",
    "PATIENT_ADMISSIONS_MERGED = PATIENT_ADMISSIONS_MERGED.drop(['Comparator'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80d43a2a-8613-4a41-a37a-64dd3a6d285e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['SUBJECT_ID', 'HADM_ID', 'ADMITTIME', 'DISCHTIME', 'DEATHTIME',\n",
      "       'ADMISSION_TYPE', 'ADMISSION_LOCATION', 'DISCHARGE_LOCATION',\n",
      "       'INSURANCE', 'LANGUAGE', 'RELIGION', 'MARITAL_STATUS', 'ETHNICITY',\n",
      "       'EDREGTIME', 'EDOUTTIME', 'DIAGNOSIS (LABEL)', 'HOSPITAL_EXPIRE_FLAG',\n",
      "       'HAS_CHARTEVENTS_DATA', 'DIAGNOSIS (ICD_9)', 'PROCEDURE TYPE'],\n",
      "      dtype='object')\n",
      "(378, 20)\n",
      "Index(['SUBJECT_ID', 'HADM_ID', 'ADMITTIME', 'DISCHTIME', 'DEATHTIME',\n",
      "       'ADMISSION_TYPE', 'ADMISSION_LOCATION', 'DISCHARGE_LOCATION',\n",
      "       'INSURANCE', 'LANGUAGE', 'RELIGION', 'MARITAL_STATUS', 'ETHNICITY',\n",
      "       'EDREGTIME', 'EDOUTTIME', 'DIAGNOSIS (LABEL)', 'HOSPITAL_EXPIRE_FLAG',\n",
      "       'HAS_CHARTEVENTS_DATA', 'DIAGNOSIS (ICD_9)', 'PROCEDURE TYPE'],\n",
      "      dtype='object')\n",
      "(58440, 20)\n"
     ]
    }
   ],
   "source": [
    "#Thomas's logic retained below\n",
    "\n",
    "print(PATIENT_ADMISSIONS_MERGED.columns)\n",
    "print(PATIENT_ADMISSIONS_MERGED.shape)\n",
    "\n",
    "print(CONTROL_ADMISSIONS_MERGED.columns)\n",
    "print(CONTROL_ADMISSIONS_MERGED.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3c7abe9-6203-496b-9686-8397c5a8f263",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunksize = 50000\n",
    "LAB_EVENTS = pd.read_csv(r\"C:\\BIOE5860_Data\\LABEVENTS.csv\",chunksize=chunksize)\n",
    "LAB_IDS = pd.read_csv(r\"C:\\BIOE5860_Data\\Lab_Item_Codes.txt\", sep=\"\\t\")\n",
    "\n",
    "PATIENT_LAB_EVENTS2 = []\n",
    "CONTROL_LAB_EVENTS2 = []\n",
    "\n",
    "\n",
    "labs_of_interest = [\n",
    "    'TROPONIN', 'D-DIMER', 'CREATININE', 'LACTATE', \n",
    "    'HEMOGLOBIN', 'HEMATOCRIT', 'CK-MB', 'BUN', \n",
    "    'UREA', 'PROCALCITONIN', 'C-REACTIVE', 'CRP', \n",
    "    'PLATELET', 'FIBRINOGEN', 'LDH', 'LACTATE DEHYDROGENASE', \n",
    "    'BILIRUBIN', 'AST', 'ALT', 'GLUCOSE', \n",
    "    'WHITE BLOOD', 'WBC', 'LYMPHOCYTE', 'NEUTROPHIL'\n",
    "]\n",
    "\n",
    "#create one large string which the string matcher will search through\n",
    "pattern = '|'.join(labs_of_interest)\n",
    "\n",
    "#check for any of the strings listed above in the pattern mega-string\n",
    "lab_ids = LAB_IDS[\n",
    "    LAB_IDS['Display'].str.contains(pattern, case=False, na=False)\n",
    "]\n",
    "lab_ids = lab_ids['Code']\n",
    "\n",
    "for EVENT in LAB_EVENTS:\n",
    "\n",
    "    EVENT = EVENT.loc[\n",
    "        EVENT['ITEMID'].isin(lab_ids)\n",
    "    ]\n",
    "    \n",
    "    #Identify all patient labs for patients who were diagnosed with AD at any point\n",
    "    PATIENT_LAB_EVENTS = EVENT[EVENT['SUBJECT_ID'].isin(AD_SUBJECT_ID)]\n",
    "    \n",
    "    #pull control group lab events as well\n",
    "    CONTROL_LAB_EVENTS = EVENT[EVENT['SUBJECT_ID'].isin(CONTROL_SUBJECT_ID)]\n",
    "    \n",
    "    #Remove redundant rows\n",
    "    PATIENT_LAB_EVENTS = PATIENT_LAB_EVENTS.drop(['ROW_ID','VALUE'],axis=1)\n",
    "    CONTROL_LAB_EVENTS = CONTROL_LAB_EVENTS.drop(['ROW_ID','VALUE'],axis=1)\n",
    "    \n",
    "    #Convert CHARTTIME to a datetime for sorting\n",
    "    PATIENT_LAB_EVENTS['CHARTTIME'] = pd.to_datetime(PATIENT_LAB_EVENTS[\"CHARTTIME\"], errors=\"coerce\")\n",
    "    CONTROL_LAB_EVENTS['CHARTTIME'] = pd.to_datetime(CONTROL_LAB_EVENTS[\"CHARTTIME\"], errors=\"coerce\")\n",
    "    \n",
    "    #Only return values that are not na.\n",
    "    PATIENT_LAB_EVENTS = PATIENT_LAB_EVENTS[PATIENT_LAB_EVENTS['HADM_ID'].notna()]\n",
    "    CONTROL_LAB_EVENTS = CONTROL_LAB_EVENTS[CONTROL_LAB_EVENTS['HADM_ID'].notna()]\n",
    "\n",
    "    PATIENT_LAB_EVENTS2.append(PATIENT_LAB_EVENTS)\n",
    "    CONTROL_LAB_EVENTS2.append(CONTROL_LAB_EVENTS)\n",
    "    \n",
    "#Remove LAB_EVENTS to conserve lots of memory since we already have extracted the necessary data\n",
    "del LAB_EVENTS\n",
    "\n",
    "#Construct final labs DFs through concatenation\n",
    "FINAL_PATIENT_LABS = pd.concat(PATIENT_LAB_EVENTS2)\n",
    "FINAL_CONTROL_LABS = pd.concat(CONTROL_LAB_EVENTS2)\n",
    "\n",
    "FINAL_PATIENT_LABS.to_csv(r\"C:\\BIOE5860_Data\\FINAL_PATIENT_LABS.csv\", index=False)\n",
    "FINAL_CONTROL_LABS.to_csv(r\"C:\\BIOE5860_Data\\FINAL_CONTROL_LABS.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74a02418",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_event_index_filter(PATIENT_ADMISSIONS_MERGED, CONTROL_ADMISSIONS_MERGED, AD_HADM_ID):\n",
    "\n",
    "    PATIENT_ADMISSIONS_MERGED = PATIENT_ADMISSIONS_MERGED.copy()\n",
    "    CONTROL_ADMISSIONS_MERGED = CONTROL_ADMISSIONS_MERGED.copy()\n",
    "\n",
    "    PATIENT_ADMISSIONS_MERGED[\"ADMITTIME\"] = pd.to_datetime(\n",
    "        PATIENT_ADMISSIONS_MERGED[\"ADMITTIME\"], errors=\"coerce\"\n",
    "    )\n",
    "\n",
    "    CONTROL_ADMISSIONS_MERGED[\"ADMITTIME\"] = pd.to_datetime(\n",
    "        CONTROL_ADMISSIONS_MERGED[\"ADMITTIME\"], errors=\"coerce\"\n",
    "    )\n",
    "\n",
    "    PATIENT_ADMISSIONS_MERGED = PATIENT_ADMISSIONS_MERGED.sort_values(\n",
    "        [\"SUBJECT_ID\", \"ADMITTIME\"]\n",
    "    )\n",
    "\n",
    "    \"\"\"\n",
    "    PATIENT_ADMISSIONS_MERGED[\"PATIENT_ADMISSION_INDEX\"] = (\n",
    "        PATIENT_ADMISSIONS_MERGED\n",
    "        .groupby(\"SUBJECT_ID\")\n",
    "        .cumcount() + 1\n",
    "    )\n",
    "    \"\"\"\n",
    "\n",
    "    DISEASE_ADMISSIONS = PATIENT_ADMISSIONS_MERGED[\n",
    "        PATIENT_ADMISSIONS_MERGED[\"HADM_ID\"].isin(AD_HADM_ID)\n",
    "    ].copy()\n",
    "\n",
    "    DISEASE_ADMISSIONS = DISEASE_ADMISSIONS.sort_values(\n",
    "        [\"SUBJECT_ID\", \"ADMITTIME\"]\n",
    "    )\n",
    "\n",
    "    DISEASE_FIRST_ADMISSIONS = (\n",
    "        DISEASE_ADMISSIONS\n",
    "        .groupby(\"SUBJECT_ID\", as_index=False)[\"ADMITTIME\"]\n",
    "        .min()\n",
    "        .rename(columns={\"ADMITTIME\": \"Comparator\"})\n",
    "    )\n",
    "\n",
    "    PATIENT_ADMISSIONS_MERGED = PATIENT_ADMISSIONS_MERGED.merge(\n",
    "        DISEASE_FIRST_ADMISSIONS,\n",
    "        on=\"SUBJECT_ID\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    PATIENT_ADMISSIONS_MERGED = PATIENT_ADMISSIONS_MERGED[\n",
    "        (PATIENT_ADMISSIONS_MERGED[\"Comparator\"].isna()) |\n",
    "        (PATIENT_ADMISSIONS_MERGED[\"ADMITTIME\"] <= PATIENT_ADMISSIONS_MERGED[\"Comparator\"])\n",
    "    ]\n",
    "\n",
    "    PATIENT_ADMISSIONS_MERGED.loc[PATIENT_ADMISSIONS_MERGED[\"Comparator\"].notna(), \"PATIENT_ADMISSION_INDEX\"] = (\n",
    "        PATIENT_ADMISSIONS_MERGED[PATIENT_ADMISSIONS_MERGED[\"Comparator\"].notna()]\n",
    "        .groupby(\"SUBJECT_ID\")[\"ADMITTIME\"]\n",
    "        .rank(method=\"first\", ascending=False)\n",
    "        .astype(int) - 1\n",
    "    )\n",
    "    \n",
    "    PATIENT_ADMISSIONS_MERGED[\"PATIENT_ADMISSION_INDEX\"] = PATIENT_ADMISSIONS_MERGED[\"PATIENT_ADMISSION_INDEX\"].astype(\"float\")\n",
    "\n",
    "    PATIENT_ADMISSIONS_MERGED = PATIENT_ADMISSIONS_MERGED.drop(columns=[\"Comparator\"])\n",
    "\n",
    "    # Keep control DF columns consistent\n",
    "    CONTROL_ADMISSIONS_MERGED[\"ADMISSION_INDEX_PER_PATIENT\"] = np.nan\n",
    "\n",
    "    return PATIENT_ADMISSIONS_MERGED, CONTROL_ADMISSIONS_MERGED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "944292af",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATIENT_ADMISSIONS_MERGED, CONTROL_ADMISSIONS_MERGED = apply_event_index_filter(PATIENT_ADMISSIONS_MERGED, CONTROL_ADMISSIONS_MERGED, AD_HADM_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "373a8875-2261-4d82-84ac-923810f87831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['SUBJECT_ID', 'HADM_ID', 'ADMITTIME', 'DISCHTIME', 'DEATHTIME',\n",
      "       'ADMISSION_TYPE', 'ADMISSION_LOCATION', 'DISCHARGE_LOCATION',\n",
      "       'INSURANCE', 'LANGUAGE', 'RELIGION', 'MARITAL_STATUS', 'ETHNICITY',\n",
      "       'EDREGTIME', 'EDOUTTIME', 'DIAGNOSIS (LABEL)', 'HOSPITAL_EXPIRE_FLAG',\n",
      "       'HAS_CHARTEVENTS_DATA', 'DIAGNOSIS (ICD_9)', 'PROCEDURE TYPE',\n",
      "       'PATIENT_ADMISSION_INDEX'],\n",
      "      dtype='object')\n",
      "(378, 21)\n",
      "Index(['SUBJECT_ID', 'HADM_ID', 'ADMITTIME', 'DISCHTIME', 'DEATHTIME',\n",
      "       'ADMISSION_TYPE', 'ADMISSION_LOCATION', 'DISCHARGE_LOCATION',\n",
      "       'INSURANCE', 'LANGUAGE', 'RELIGION', 'MARITAL_STATUS', 'ETHNICITY',\n",
      "       'EDREGTIME', 'EDOUTTIME', 'DIAGNOSIS (LABEL)', 'HOSPITAL_EXPIRE_FLAG',\n",
      "       'HAS_CHARTEVENTS_DATA', 'DIAGNOSIS (ICD_9)', 'PROCEDURE TYPE',\n",
      "       'ADMISSION_INDEX_PER_PATIENT'],\n",
      "      dtype='object')\n",
      "(58440, 21)\n"
     ]
    }
   ],
   "source": [
    "#display unique ICD9 codes in the filtered patient admissions\n",
    "#print(PATIENT_ADMISSIONS_MERGED['DIAGNOSIS (ICD_9)'].explode().unique())\n",
    "#print(CONTROL_ADMISSIONS_MERGED['DIAGNOSIS (ICD_9)'].explode().unique())\n",
    "\n",
    "print(PATIENT_ADMISSIONS_MERGED.columns)\n",
    "print(PATIENT_ADMISSIONS_MERGED.shape)\n",
    "print(CONTROL_ADMISSIONS_MERGED.columns)\n",
    "print(CONTROL_ADMISSIONS_MERGED.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92392489",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATIENT_ADMISSIONS_MERGED.to_csv(r\"C:\\BIOE5860_Data\\PATIENT_ADMISSIONS_MERGED.csv\", index=False)\n",
    "CONTROL_ADMISSIONS_MERGED.to_csv(r\"C:\\BIOE5860_Data\\CONTROL_ADMISSIONS_MERGED.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e968bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "17\n",
      "{83040, 56898, 41603, 26308, 25828, 5353, 682, 19914, 24652, 48078, 31377, 16181, 21206, 95030, 13208, 6938, 5183}\n",
      "Index(['SUBJECT_ID', 'HADM_ID', 'ADMITTIME', 'DISCHTIME', 'DEATHTIME',\n",
      "       'ADMISSION_TYPE', 'ADMISSION_LOCATION', 'DISCHARGE_LOCATION',\n",
      "       'INSURANCE', 'LANGUAGE', 'RELIGION', 'MARITAL_STATUS', 'ETHNICITY',\n",
      "       'EDREGTIME', 'EDOUTTIME', 'DIAGNOSIS (LABEL)', 'HOSPITAL_EXPIRE_FLAG',\n",
      "       'HAS_CHARTEVENTS_DATA', 'DIAGNOSIS (ICD_9)', 'PROCEDURE TYPE',\n",
      "       'PATIENT_ADMISSION_INDEX'],\n",
      "      dtype='object')\n",
      "(378, 21)\n",
      "Index(['SUBJECT_ID', 'HADM_ID', 'ADMITTIME', 'DISCHTIME', 'DEATHTIME',\n",
      "       'ADMISSION_TYPE', 'ADMISSION_LOCATION', 'DISCHARGE_LOCATION',\n",
      "       'INSURANCE', 'LANGUAGE', 'RELIGION', 'MARITAL_STATUS', 'ETHNICITY',\n",
      "       'EDREGTIME', 'EDOUTTIME', 'DIAGNOSIS (LABEL)', 'HOSPITAL_EXPIRE_FLAG',\n",
      "       'HAS_CHARTEVENTS_DATA', 'DIAGNOSIS (ICD_9)', 'PROCEDURE TYPE',\n",
      "       'ADMISSION_INDEX_PER_PATIENT'],\n",
      "      dtype='object')\n",
      "(58440, 21)\n"
     ]
    }
   ],
   "source": [
    "#this script finds all patients who have 'AORTIC DISSECTION' in their ADMISSIONS DIAGNOSIS text field\n",
    "#but do not have the corresponding ICD9 code in DIAGNOSES_ICD\n",
    "#my_icd9_code = [whatever yours is]\n",
    " \n",
    "aortic_ids = ADMISSIONS[ADMISSIONS['DIAGNOSIS'].str.contains('AORTIC DISSECTION', na=False)]['SUBJECT_ID'].unique()\n",
    " \n",
    "\"\"\"\n",
    "AD_SUBJECT_ID = DIAGNOSES_ICD.loc[\n",
    "    DIAGNOSES_ICD[\"ICD9_CODE\"].astype(str).isin(my_icd9_code),\n",
    "    \"SUBJECT_ID\"\n",
    "].unique()\n",
    "\"\"\"\n",
    " \n",
    "#aortic_patients = PATIENT_DIAGNOSES[PATIENT_DIAGNOSES['SUBJECT_ID']].unique()\n",
    " \n",
    "#find patients who have AORTIC DISSECTION text but don't have the ICD9 code from my_icd9_code\n",
    "\n",
    "difference = set(aortic_ids) - set(AD_SUBJECT_ID)\n",
    "print(len(set(difference) & set(CONTROL_SUBJECT_ID))) #if this is 0 then all were successfully removed in first cell\n",
    "\n",
    "print(len(difference))\n",
    "print(difference)\n",
    " \n",
    "#remove all subject IDs found above from CONTROL_SUBJECT_ID since we don't know if they are actually controls \n",
    "#or if they are patients with AD who just don't have the correct ICD9 code in the DIAGNOSES_ICD file\n",
    "#CONTROL_SUBJECT_ID = CONTROL_SUBJECT_ID[~np.isin(CONTROL_SUBJECT_ID, list(difference))]\n",
    "\n",
    "#PATIENT_ADMISSIONS_MERGED.to_csv(r\"C:\\BIOE5860_Data\\PATIENT_ADMISSIONS_MERGED.csv\", index=False)\n",
    "#CONTROL_ADMISSIONS_MERGED.to_csv(r\"C:\\BIOE5860_Data\\CONTROL_ADMISSIONS_MERGED.csv\", index=False)\n",
    "\n",
    "print(PATIENT_ADMISSIONS_MERGED.columns)\n",
    "print(PATIENT_ADMISSIONS_MERGED.shape)\n",
    "print(CONTROL_ADMISSIONS_MERGED.columns)\n",
    "print(CONTROL_ADMISSIONS_MERGED.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
